<!DOCTYPE html>
<html>
<head>
  <meta name="databricks-html-version" content="1">
<title>bbuzz2016-backup - Databricks</title>

<meta charset="utf-8">
<meta name="google" content="notranslate">
<meta http-equiv="Content-Language" content="en">
<meta http-equiv="Content-Type" content="text/html; charset=UTF8">
<link rel="stylesheet"
  href="https://fonts.googleapis.com/css?family=Source+Code+Pro:400,700">

<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201606061046110700-7b6903d79ff87bc92783c273ec9805efdd9a8110/lib/css/bootstrap.min.css">
<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201606061046110700-7b6903d79ff87bc92783c273ec9805efdd9a8110/lib/jquery-ui-bundle/jquery-ui.min.css">
<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201606061046110700-7b6903d79ff87bc92783c273ec9805efdd9a8110/css/main.css">
<link rel="stylesheet" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201606061046110700-7b6903d79ff87bc92783c273ec9805efdd9a8110/css/print.css" media="print">
<link rel="icon" type="image/png" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/201606061046110700-7b6903d79ff87bc92783c273ec9805efdd9a8110/img/favicon.ico"/>
<script>window.settings = {"enableAutoCompleteAsYouType":[],"devTierName":"Community Edition","workspaceFeaturedLinks":[{"linkURI":"https://docs.cloud.databricks.com/docs/latest/databricks_guide/index.html","displayName":"Databricks Guide","icon":"question"},{"linkURI":"https://docs.cloud.databricks.com/docs/latest/sample_applications/index.html","displayName":"Application Examples","icon":"code"},{"linkURI":"https://docs.cloud.databricks.com/docs/latest/courses/index.html","displayName":"Training","icon":"graduation-cap"}],"dbcForumURL":"http://forums.databricks.com/","nodeInfo":{"node_types":[{"spark_heap_memory":4800,"instance_type_id":"r3.2xlarge","spark_core_oversubscription_factor":3.0,"node_type_id":"dev-tier-node","description":"Community Optimized","container_memory_mb":6000,"memory_mb":6144,"num_cores":0.88}],"default_node_type_id":"dev-tier-node"},"enableThirdPartyApplicationsUI":false,"enableClusterAcls":false,"notebookRevisionVisibilityHorizon":999999,"enableTableHandler":true,"isAdmin":true,"enableLargeResultDownload":true,"zoneInfos":[{"id":"us-west-2c","isDefault":true},{"id":"us-west-2b","isDefault":false},{"id":"us-west-2a","isDefault":false}],"enablePublishNotebooks":true,"enableJobAclsConfig":false,"enableFullTextSearch":false,"enableElasticSparkUI":false,"clusters":true,"allowRunOnPendingClusters":true,"applications":false,"fileStoreBase":"FileStore","configurableSparkOptionsSpec":[{"keyPattern":"spark\\.kryo(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.kryo.*","valuePatternDisplay":"*","description":"Configuration options for Kryo serialization"},{"keyPattern":"spark\\.io\\.compression\\.codec","valuePattern":"(lzf|snappy|org\\.apache\\.spark\\.io\\.LZFCompressionCodec|org\\.apache\\.spark\\.io\\.SnappyCompressionCodec)","keyPatternDisplay":"spark.io.compression.codec","valuePatternDisplay":"snappy|lzf","description":"The codec used to compress internal data such as RDD partitions, broadcast variables and shuffle outputs."},{"keyPattern":"spark\\.serializer","valuePattern":"(org\\.apache\\.spark\\.serializer\\.JavaSerializer|org\\.apache\\.spark\\.serializer\\.KryoSerializer)","keyPatternDisplay":"spark.serializer","valuePatternDisplay":"org.apache.spark.serializer.JavaSerializer|org.apache.spark.serializer.KryoSerializer","description":"Class to use for serializing objects that will be sent over the network or need to be cached in serialized form."},{"keyPattern":"spark\\.rdd\\.compress","valuePattern":"(true|false)","keyPatternDisplay":"spark.rdd.compress","valuePatternDisplay":"true|false","description":"Whether to compress serialized RDD partitions (e.g. for StorageLevel.MEMORY_ONLY_SER). Can save substantial space at the cost of some extra CPU time."},{"keyPattern":"spark\\.speculation","valuePattern":"(true|false)","keyPatternDisplay":"spark.speculation","valuePatternDisplay":"true|false","description":"Whether to use speculation (recommended off for streaming)"},{"keyPattern":"spark\\.es(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"es(\\.([^\\.]+))+","valuePattern":".*","keyPatternDisplay":"es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"spark\\.(storage|shuffle)\\.memoryFraction","valuePattern":"0?\\.0*([1-9])([0-9])*","keyPatternDisplay":"spark.(storage|shuffle).memoryFraction","valuePatternDisplay":"(0.0,1.0)","description":"Fraction of Java heap to use for Spark's shuffle or storage"},{"keyPattern":"spark\\.streaming\\.backpressure\\.enabled","valuePattern":"(true|false)","keyPatternDisplay":"spark.streaming.backpressure.enabled","valuePatternDisplay":"true|false","description":"Enables or disables Spark Streaming's internal backpressure mechanism (since 1.5). This enables the Spark Streaming to control the receiving rate based on the current batch scheduling delays and processing times so that the system receives only as fast as the system can process. Internally, this dynamically sets the maximum receiving rate of receivers. This rate is upper bounded by the values `spark.streaming.receiver.maxRate` and `spark.streaming.kafka.maxRatePerPartition` if they are set."},{"keyPattern":"spark\\.streaming\\.receiver\\.maxRate","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.receiver.maxRate","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which each receiver will receive data. Effectively, each stream will consume at most this number of records per second. Setting this configuration to 0 or a negative number will put no limit on the rate. See the deployment guide in the Spark Streaming programing guide for mode details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRatePerPartition","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRatePerPartition","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which data will be read from each Kafka partition when using the Kafka direct stream API introduced in Spark 1.3. See the Kafka Integration guide for more details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRetries","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRetries","valuePatternDisplay":"numeric","description":"Maximum number of consecutive retries the driver will make in order to find the latest offsets on the leader of each partition (a default value of 1 means that the driver will make a maximum of 2 attempts). Only applies to the Kafka direct stream API introduced in Spark 1.3."},{"keyPattern":"spark\\.streaming\\.ui\\.retainedBatches","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.ui.retainedBatches","valuePatternDisplay":"numeric","description":"How many batches the Spark Streaming UI and status APIs remember before garbage collecting."}],"enableReactNotebookComments":true,"enableResetPassword":true,"enableJobsSparkUpgrade":true,"sparkVersions":[{"key":"1.6.x-ubuntu15.10","displayName":"Spark 1.6.x (Hadoop 1)","packageLabel":"spark-1.6.1-hadoop1-jenkins-ip-10-30-10-144-U7b23adafbe-S2368283920-2016-05-18-22:17:18.107960","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"1.4.x-ubuntu15.10","displayName":"Spark 1.4.1 (Hadoop 1)","packageLabel":"spark-1.4-jenkins-ip-10-30-10-144-U7b23adafbe-S9c254ab12a-2016-05-18-22:17:18.107960","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.x-ubuntu15.10-hadoop1","displayName":"Spark 1.6.x (Hadoop 1)","packageLabel":"spark-1.6.1-hadoop1-jenkins-ip-10-30-10-144-U7b23adafbe-S2368283920-2016-05-18-22:17:18.107960","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"1.6.1-ubuntu15.10-hadoop1","displayName":"Spark 1.6.1 (Hadoop 1)","packageLabel":"spark-1.6.1-hadoop1-jenkins-ip-10-30-10-144-U7b23adafbe-S2368283920-2016-05-18-22:17:18.107960","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.1-ubuntu15.10-hadoop2","displayName":"Spark 1.6.1 (Hadoop 2)","packageLabel":"spark-1.6.1-hadoop2-jenkins-ip-10-30-10-144-U7b23adafbe-S2368283920-2016-05-18-22:17:18.107960","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.5.x-ubuntu15.10","displayName":"Spark 1.5.2 (Hadoop 1)","packageLabel":"spark-1.5-jenkins-ip-10-30-10-144-U7b23adafbe-S9ca52d000d-2016-05-18-22:17:18.107960","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.3.x-ubuntu15.10","displayName":"Spark 1.3.0 (Hadoop 1)","packageLabel":"spark-1.3-jenkins-ip-10-30-10-144-U7b23adafbe-Sa2ee4664b2-2016-05-18-22:17:18.107960","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.x-ubuntu15.10","displayName":"Spark 2.0 (apache/branch-2.0 preview)","packageLabel":"spark-image-15bcfbcb493bf981225c4020ab1183871d4bebfe40135d190e5d4993f4de6fe3","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.0-ubuntu15.10","displayName":"Spark 1.6.0 (Hadoop 1)","packageLabel":"spark-1.6.0-jenkins-ip-10-30-10-144-U7b23adafbe-Sf90f83597b-2016-05-18-22:17:18.107960","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.x-ubuntu15.10-hadoop2","displayName":"Spark 1.6.x (Hadoop 2)","packageLabel":"spark-1.6.1-hadoop2-jenkins-ip-10-30-10-144-U7b23adafbe-S2368283920-2016-05-18-22:17:18.107960","upgradable":true,"deprecated":false,"customerVisible":false}],"enableRestrictedClusterCreation":true,"enableFeedback":true,"enableClusterAutoScaling":false,"defaultNumWorkers":0,"serverContinuationTimeoutMillis":10000,"driverStderrFilePrefix":"stderr","enableNotebookRefresh":false,"driverStdoutFilePrefix":"stdout","enableSparkDocsSearch":true,"sparkHistoryServerEnabled":true,"sanitizeMarkdownHtml":true,"enableIPythonImportExport":true,"enableNotebookHistoryDiffing":true,"branch":"2.20","accountsLimit":3,"enableNotebookGitBranching":true,"local":false,"enableStrongPassword":false,"displayDefaultContainerMemoryGB":6,"deploymentMode":"production","useSpotForWorkers":true,"enableUserInviteWorkflow":true,"enableStaticNotebooks":true,"enableCssTransitions":true,"showHomepageFeaturedLinks":true,"pricingURL":"https://databricks.com/product/pricing","enableClusterAclsConfig":false,"notifyLastLogin":false,"enableNotebookGitVersioning":true,"files":"files/","enableDriverLogsUI":true,"disableLegacyDashboards":true,"enableWorkspaceAclsConfig":false,"dropzoneMaxFileSize":4096,"enableNewDashboardViews":true,"driverLog4jFilePrefix":"log4j","enableSingleSignOn":false,"enableMavenLibraries":true,"displayRowLimit":1000,"defaultSparkVersion":{"key":"1.6.1-ubuntu15.10-hadoop1","displayName":"Spark 1.6.1 (Hadoop 1)","packageLabel":"spark-1.6.1-hadoop1-jenkins-ip-10-30-10-144-U7b23adafbe-S2368283920-2016-05-18-22:17:18.107960","upgradable":true,"deprecated":false,"customerVisible":true},"enableMountAclsConfig":false,"enableClusterAclsByTier":false,"disallowAddingAdmins":true,"enableSparkConfUI":true,"featureTier":"DEVELOPER_BASIC_TIER","enableOrgSwitcherUI":true,"clustersLimit":1,"enableJdbcImport":true,"logfiles":"logfiles/","enableWebappSharding":true,"enableClusterDeltaUpdates":true,"enableSingleSignOnLogin":false,"useFixedStaticNotebookVersionForDevelopment":false,"enableMountAcls":false,"requireEmailUserName":true,"enableDashboardViews":false,"dbcFeedbackURL":"mailto:feedback@databricks.com","enableMountAclService":true,"enableWorkspaceAclService":true,"enableWorkspaceAcls":false,"gitHash":"7b6903d79ff87bc92783c273ec9805efdd9a8110","showWorkspaceFeaturedLinks":true,"signupUrl":"https://databricks.com/try-databricks","allowFeedbackForumAccess":true,"enableImportFromUrl":true,"enableMiniClusters":true,"showDevTierBetaVersion":true,"enableDebugUI":false,"allowNonAdminUsers":true,"enableSingleSignOnByTier":false,"staticNotebookResourceUrl":"https://databricks-prod-cloudfront.cloud.databricks.com/static/201606061046110700-7b6903d79ff87bc92783c273ec9805efdd9a8110/","enableSparkPackages":true,"dynamicSparkVersions":true,"enableNotebookHistoryUI":true,"showDebugCounters":false,"enableFolderHtmlExport":true,"enableSparkVersionsUI":true,"homepageFeaturedLinks":[{"linkURI":"https://docs.cloud.databricks.com/docs/latest/featured_notebooks/A%20Gentle%20Introduction%20to%20Apache%20Spark%20on%20Databricks.html","displayName":"Introduction to Apache Spark on Databricks","icon":"img/home/Python_icon.svg"},{"linkURI":"https://docs.cloud.databricks.com/docs/latest/featured_notebooks/Quick%20Start%20DataFrames.html","displayName":"Quick Start DataFrames","icon":"img/home/Scala_icon.svg"},{"linkURI":"https://docs.cloud.databricks.com/docs/latest/featured_notebooks/GSW%20Passing%20Analysis%20(new).html","displayName":"GSW Passing Analysis (new)","icon":"img/home/Python_icon.svg"}],"upgradeURL":"https://accounts.cloud.databricks.com/registration.html#login","notebookLoadingBackground":"#fff","enableServerAutoComplete":true,"enableStaticHtmlImport":true,"enableTerminal":false,"defaultMemoryPerContainerMB":6000,"enablePresenceUI":true,"accounts":true,"useFramedStaticNotebooks":true,"enableNewProgressReportUI":true,"defaultCoresPerContainer":4};</script>
<script>var __DATABRICKS_NOTEBOOK_MODEL = {"version":"NotebookV1","origId":183210672370542,"name":"bbuzz2016-backup","language":"python","commands":[{"version":"CommandV1","origId":183210672370544,"guid":"48910ba8-f720-461a-802b-bdb7c4155f4e","subtype":"command","commandType":"auto","position":1.0,"command":"import re\nfrom pyspark.sql import Row\nfrom pyspark.sql.types import ArrayType, StringType","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.465307756191E12,"submitTime":1.46530775734E12,"finishTime":1.465307756234E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"Imports","showCommandTitle":true,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"08e5da6b-1200-400c-a55e-78c8004ebe64"},{"version":"CommandV1","origId":2469000391151274,"guid":"baf06522-c19c-4ac0-b041-20fa61496b82","subtype":"command","commandType":"auto","position":1.5,"command":"MY_AWS_ACCESS_KEY = \"YOUR_AWS_ACCESS_KEY_HERE\"\nMY_AWS_SECRET_KEY = \"YOUR_AWS_SECRET_HERE\"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.465307758086E12,"submitTime":1.465307759225E12,"finishTime":1.465307758161E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"AWS Credentials (Secret!!!!1eleven!!)","showCommandTitle":true,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"bf03e34b-c2b1-486a-b865-c75c089bde2a"},{"version":"CommandV1","origId":183210672370549,"guid":"a6cdccf9-1493-4027-a7a2-d67a20b4a1c6","subtype":"command","commandType":"auto","position":2.0,"command":"import urllib\nACCESS_KEY = MY_AWS_ACCESS_KEY\nSECRET_KEY = MY_AWS_SECRET_KEY\nENCODED_SECRET_KEY = urllib.quote(SECRET_KEY, \"\")\nAWS_BUCKET_NAME = \"bbuzz2016\" # AWS_BUCKET_NAME = \"bbuzz2016data\" \nMOUNT_NAME = \"bbuzz2016\" # MOUNT_NAME = \"bbuzz2016data\"\ndbutils.fs.mount(\"s3n://%s:%s@%s\" % (ACCESS_KEY, ENCODED_SECRET_KEY, AWS_BUCKET_NAME), \"/mnt/%s\" % MOUNT_NAME)","commandVersion":0,"state":"error","results":null,"errorSummary":"java.rmi.RemoteException: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/bbuzz2016; nested exception is: ","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">ExecutionError</span>                            Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-4-29abd34a2f21&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      5</span> AWS_BUCKET_NAME <span class=\"ansiyellow\">=</span> <span class=\"ansiblue\">&quot;bbuzz2016&quot;</span> <span class=\"ansired\"># AWS_BUCKET_NAME = &quot;bbuzz2016data&quot;</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      6</span> MOUNT_NAME <span class=\"ansiyellow\">=</span> <span class=\"ansiblue\">&quot;bbuzz2016&quot;</span> <span class=\"ansired\"># MOUNT_NAME = &quot;bbuzz2016data&quot;</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 7</span><span class=\"ansiyellow\"> </span>dbutils<span class=\"ansiyellow\">.</span>fs<span class=\"ansiyellow\">.</span>mount<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;s3n://%s:%s@%s&quot;</span> <span class=\"ansiyellow\">%</span> <span class=\"ansiyellow\">(</span>ACCESS_KEY<span class=\"ansiyellow\">,</span> ENCODED_SECRET_KEY<span class=\"ansiyellow\">,</span> AWS_BUCKET_NAME<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">,</span> <span class=\"ansiblue\">&quot;/mnt/%s&quot;</span> <span class=\"ansiyellow\">%</span> MOUNT_NAME<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/tmp/1465307751123-0/dbutils.py</span> in <span class=\"ansicyan\">f_with_exception_handling</span><span class=\"ansiblue\">(*args, **kwargs)</span>\n<span class=\"ansigreen\">    160</span>                     <span class=\"ansigreen\">class</span> ExecutionError<span class=\"ansiyellow\">(</span>BaseException<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    161</span>                         <span class=\"ansigreen\">pass</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 162</span><span class=\"ansiyellow\">                     </span><span class=\"ansigreen\">raise</span> ExecutionError<span class=\"ansiyellow\">(</span>str<span class=\"ansiyellow\">(</span>e<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    163</span>             <span class=\"ansigreen\">return</span> f_with_exception_handling<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    164</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">ExecutionError</span>: An error occurred while calling o90.mount.\n: java.rmi.RemoteException: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/bbuzz2016; nested exception is: \n\tjava.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/bbuzz2016\n\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:73)\n\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:42)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.mount(DBUtilsCore.scala:315)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\n\tat py4j.Gateway.invoke(Gateway.java:259)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:209)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/bbuzz2016\n\tat scala.Predef$.require(Predef.scala:233)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.insertMount(MetadataManager.scala:121)\n\tat com.databricks.backend.daemon.data.server.handler.MountHandler.receive(MountHandler.scala:38)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext$$anonfun$queryHandlers$1.apply(SessionContext.scala:58)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext$$anonfun$queryHandlers$1.apply(SessionContext.scala:57)\n\tat scala.collection.immutable.List.foreach(List.scala:318)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.queryHandlers(SessionContext.scala:57)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$1.applyOrElse(DbfsServerBackend.scala:214)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$1.applyOrElse(DbfsServerBackend.scala:195)\n\tat com.databricks.rpc.ServerBackend$$anonfun$internalReceive$1.applyOrElse(ServerBackend.scala:42)\n\tat com.databricks.rpc.ServerBackend$$anonfun$internalReceive$1.applyOrElse(ServerBackend.scala:37)\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:33)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:57)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:57)\n\tat scala.PartialFunction$OrElse.apply(PartialFunction.scala:162)\n\tat com.databricks.rpc.JettyServer$RequestManager$$anonfun$10.apply(JettyServer.scala:262)\n\tat scala.util.Try$.apply(Try.scala:161)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:262)\n\tat com.databricks.rpc.JettyServer$RequestManager.com$databricks$rpc$JettyServer$RequestManager$$handleRequestAndRespond(JettyServer.scala:199)\n\tat com.databricks.rpc.JettyServer$RequestManager$$anonfun$handleHttp$1.apply$mcV$sp(JettyServer.scala:144)\n\tat com.databricks.rpc.JettyServer$RequestManager$$anonfun$handleHttp$1.apply(JettyServer.scala:135)\n\tat com.databricks.rpc.JettyServer$RequestManager$$anonfun$handleHttp$1.apply(JettyServer.scala:135)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:121)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:116)\n\tat com.databricks.rpc.JettyServer$.withAttributionContext(JettyServer.scala:74)\n\tat com.databricks.logging.UsageLogging$class.withAttributionTags(UsageLogging.scala:154)\n\tat com.databricks.rpc.JettyServer$.withAttributionTags(JettyServer.scala:74)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:134)\n\tat com.databricks.rpc.JettyServer$RequestManager.doGet(JettyServer.scala:89)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:687)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:816)\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:119)\n\tat org.eclipse.jetty.server.Server.handle(Server.java:517)\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:306)\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:242)\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:245)\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:95)\n\tat org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:75)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceAndRun(ExecuteProduceConsume.java:213)\n\tat org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:147)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:654)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:572)\n\t... 1 more\n\n</div>","workflows":[],"startTime":1.465307759681E12,"submitTime":1.465307759681E12,"finishTime":1.46530776009E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"0cf85def-df3e-4ddf-8c64-640e3843a455"},{"version":"CommandV1","origId":183210672370550,"guid":"d375b425-4ba3-4675-8d43-79fbb6938f72","subtype":"command","commandType":"auto","position":2.5,"command":"display(dbutils.fs.ls(\"/mnt/bbuzz2016\"))","commandVersion":0,"state":"finished","results":{"type":"table","data":[["dbfs:/mnt/bbuzz2016/all-years.jsonlines","all-years.jsonlines",449357.0],["dbfs:/mnt/bbuzz2016/stopwords.txt","stopwords.txt",622.0]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"path","type":"\"string\""},{"name":"name","type":"\"string\""},{"name":"size","type":"\"long\""}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":null,"error":null,"workflows":[],"startTime":1.465307760881E12,"submitTime":1.465307762021E12,"finishTime":1.465307764585E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"2ba00a8b-209c-4a5d-a31f-a262c68379d1"},{"version":"CommandV1","origId":2469000391151330,"guid":"9bce2c60-0ad0-4bad-bcc8-a25851c0d921","subtype":"command","commandType":"auto","position":2.6875,"command":"bbuzz = sqlContext.read.json(\"dbfs:/mnt/bbuzz2016/all-years.jsonlines\")\nbbuzz.registerTempTable(\"bbuzz_raw\")","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.46530776805E12,"submitTime":1.465307769191E12,"finishTime":1.465307771874E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"Load Data","showCommandTitle":true,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"1cd831df-6ee7-4a8c-b444-e1766af3c239"},{"version":"CommandV1","origId":2469000391151331,"guid":"dd1b8359-3554-4e1d-b782-6c8a8934e2d5","subtype":"command","commandType":"auto","position":2.78125,"command":"display(sqlContext.sql(\"SELECT * FROM bbuzz_raw WHERE content <> '' LIMIT 10\"))","commandVersion":0,"state":"finished","results":{"type":"table","data":[["Learning to Rank (LTR), once the domain of academic researchers in machine learning and information retrieval, has begun to make great headway in practical applications on the web. Its tools and techniques offer a new way to think about challenges in relevance ranking, personalization, localization, ad targeting and multimedia search, but it shares enough conceptual foundations with traditional search relevance that it?s easy for hands-on engineers to get started with. In this talk, Andrew will introduce the field and its key concepts, before diving into one of its best-known algorithms, Ranking SVM, which adapts Support Vector Machines to ranking tasks instead of classification problems. With real examples taken from work at Etsy and elsewhere, he?ll talk about how you can use this algorithm and others like it to incorporate a huge variety of features into your search ranking model: query-specific term weights, implicit user feedback, temporal and geographic data, and even image features. And he?ll touch on applications of LTR beyond traditional search, including ad click prediction and content-based recommendations. No past experience of machine learning will be required. Attendees can expect to leave this talk with an understanding of LTR and its applications, and enough insight into Ranking SVM to enable them to experiment with ranking models on their own data.  ","https://www.berlinbuzzwords.de/session/learning-rank-where-search-meets-machine-learning",["andrew clegg"],"\n                  Learning to Rank: where search meets machine learning                "],["Modern cars produce data. Lots of data. And Formula 1 cars produce more than their share. I will present a working demonstration of how modern data streaming can be applied to the data acquisition and analysis problem posed by modern motorsports. Instead of bringing multiple Formula 1 cars to the talk, I will show how we instrumented a high fidelity physics-based automotive simulator to produce realistic data from simulated cars running on the Spa-Francorchamps track. We move data from the cars, to the pits, to the engineers back at HQ. The result is near real-time visualization and comparison of performance and a great exposition of how to move data using messaging systems like Kafka. The code from this talk will be made available as open source.  ","https://www.berlinbuzzwords.de/session/fast-cars-big-data-how-streaming-can-help-formula-1",["ted dunning"],"\n                  Fast Cars, Big Data - How Streaming Can Help Formula 1                "],["We observed that marketing teams of major companies tend to build their marketing campaigns based on study of client segmentation and market analysis which can be an heavy workload that directly deteriorate its ROI \nUsing our client Big Data (6 000 000 client informations on a Hadoop / Spark Cluster) we tried an other approach to dramaticaly increase the agility for building and tayloring new marketing campaigns. \nWe used Test&Learn methodolgies to increase the \"uplift\" of the campaigns inspired by the multi-armed bandit problem ( ) and implemented the whole approach in Apache Spark. \nIn this talk we want to share our feedbacks on the approach the success we had and probably more importantly the pitfalls we encountered.","https://www.berlinbuzzwords.de/session/project-use-case-improve-your-marketing-reach-using-large-scale-machine-learning-spark",["nina bertrand","matthieu vautrot"],"\n                  Project use case : Improve your marketing reach using large scale machine learning on Spark                "],["Today's industrial systems produce more and more data everyday. Companies are increasingly using Big Data technologies and data analysis approaches in order to monitor their systems. I will illustrate this trend with a project of predictive maintenance on trains. In cities where millions of people use public transportation everyday, avoiding faults on trains during circulations is critical. The goal of the project is to predict faults on trains in advance so that can be are dispatched to the workshops accordingly, thus avoiding train delays and reducing maintenance costs. I'll explain our approach which uses random forests and artificial neural networks with theano, what are the results and how we measure success, and finally how, from developing models on historical data with python, we progressively moved to production and transposed the models to a distributed environment using Spark.","https://www.berlinbuzzwords.de/session/predictive-maintenance-poc-production-spark",["heloise nonne"],"\n                  Predictive maintenance: from POC to production with Spark                "],["Hubot, GitHub's open source chat bot, is completely revolutionizing how we build, ship and operate software at scale. As a widely distributed company, we rely on online chat as one of our primary communication tools. ChatOps helps us improve situational awareness during incidents, to share knowledge, to ship software, and much more. We'll look at some concrete examples and talk about the cultural implications embracing ChatOps has had at GitHub.","https://www.berlinbuzzwords.de/session/shipping-scale-chatops-github",["georgi knox"],"\n                  Shipping at Scale: ChatOps at GitHub                "],["Lucene will change the default scoring from TF/IDF to BM25 in the next major release. So unless you really enjoy surprises you better learn about it now! TF/IDF was easy enough to understand intuitively but how is it with BM25? What do all these parameters do? And what do people mean when they say it is \"probabilistic\"? In this talk I will tell the story of how we came from the Probability Ranking Principle to BM25 with a minimum of math and a maximum of explaining. I will also show how BM25 differs from TF/IDF, what it means in practice and give and intuition on what the parameters of this method actually do. You will leave this talk feeling good about Lucene changing the default. And of course you will learn many fancy buzzwords to show off with during the breaks.","https://www.berlinbuzzwords.de/session/bm25-demystified",["britta weber"],"\n                  BM25 demystified                "],["There are lots of claims about the benefits of NoSQL databases, but few realistic demonstrations of the impact that such a database can have on anything more than toy-sized data.  In this talk, I will deconstruct a real-world database schema into the corresponding NoSQL design. The database that I will use is the Musicbrainz database, which exhibits many important idioms found in real databases, such as factoring relations into multiple tables to implement column families, linkage tables, and many-to-one relationships. In spite of such radical structural changes, the resulting denormalized and nested data can still be queried with SQL using Apache Drill, and the queries are often noticeably simpler than the queries used against the original data structures. The methods are practical and easy to apply, and can sometimes be largely automated. For example, I'll show how a percolator pattern can be used to allow the resulting NoSQL database to be automatically maintained in multiple NoSQL technologies simultaneously, so that full text search, recommendations, and the HBase API can all be used to access the same data.","https://www.berlinbuzzwords.de/session/real-world-nosql-schema-design",["tugdual grall"],"\n                  Real-World NoSQL Schema Design                "],["At the beginning of the year 2016, the Apache Lucene team decided to focus on releasing Apache Lucene 6. Around Berlin Buzzwords, the new version will be available for testing. This talk will present the new features that Lucene 6 will bring: A new data type called \"points\" (also known as dimensional values) and corresponding queries as faster, multidimensional replacement for NumericRangeQuery. It will also completely remove the concept of \"filters\" in favour of non-scoring queries. Last but not least, Lucene and Solr 6 will require Java 8 as minimum requirement. This talk will also present the many new features in Apache Solr 6: It now understands an SQL dialect to do queries and aggregations. In combination with a brand new JDBC driver, one can query Solr using standard database tools.","https://www.berlinbuzzwords.de/session/apache-lucene-6-whats-coming-next",["uwe schindler"],"\n                  Apache Lucene 6: What's coming next?                "],["We present a new design pattern for data streaming applications, using Apache Flink and Apache Kafka: Building applications directly on top of the stream processor, rather than on top of key/value databases populated by data streams. Unlike classical setups that use stream processors or libraries to pre-process/aggregate events and update a database with the results, this setup simply gives the role of the database to the stream processor (here Apache Flink), routing queries to its workers who directly answer them from their internal state computed over the log of events (Apache Kafka). This architecture pattern has many interesting implications:   - All state updates happen locally in the stream processor. This eliminates the need for (distributed) transactions with an external database, leading to very high performance (we saw cases with >100x speedup compared to pushing the state into a database).   - Consistency (exactly-once) is maintained across the entire pipeline: log, stream processor, and application state. That stands in contrast to setups today, where duplicate changes may be pushed to the database, because the database is typically not integrated with the stream processor's consistency mechanism.   - Consistency and persistence are realized through distributed snapshots. Changes between snapshots are replayed from the input streams or Kafka. When snapshots run asynchronously, the overhead of these snapshots is very low   - Because application state is part of a streaming program, one can naturally upgrade/rollback the program and state together, replay the stream with a modified program (playing through what-if scenarios) or fork off a new variant of the state (A/B testing)   - This architecture eases the handling of out of order streams and late-arriving events. The stream processor can expose early results in addition to the correct results.   This talk will cover both the high-level introduction to the architecture, the techniques in Flink/Kafka that make this approach possible, as well as experiences from a large scale setup and technical details.","https://www.berlinbuzzwords.de/session/stream-processor-database-building-online-applications-directly-streams-apache-flink-and",["stephan ewen"],"\n                  The Stream Processor as a Database: Building Online Applications directly on Streams with Apache Flink and Apache Kafka                "],["\nIn this session, you will get your hands on stream processing with Apache Flink, an open source platform for distributed stream and batch processing. \nWe will introduce Flink's DataStream API and help you to setup a local development environment to implement and test scalable stream processing programs. \nHands-on coding exercises will make this a fun session to attend. Please note: This is a hands-on session. You should be familiar with Java or Scala and bring a laptop. \nWe recommend to prepare the Flink setup by following these instructions ( ) in advance to save some time.","https://www.berlinbuzzwords.de/session/getting-started-stream-processing-apache-flink",["maximilian michels","vasia kalavri","fabian hueske"],"\n                  Getting started with Stream Processing on Apache Flink                "]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"content","type":"\"string\""},{"name":"link","type":"\"string\""},{"name":"speakers","type":"{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"},{"name":"title","type":"\"string\""}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":null,"error":null,"workflows":[],"startTime":1.465307773334E12,"submitTime":1.465307774472E12,"finishTime":1.46530777708E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"dabfb129-2b67-497b-b418-8da1726f2576"},{"version":"CommandV1","origId":2469000391151333,"guid":"628da307-183e-4a79-b9f6-0dbfa18616dd","subtype":"command","commandType":"auto","position":2.7841796875,"command":"display(sql(\"SELECT lower(content) FROM bbuzz_raw WHERE content <> '' LIMIT 10\"))","commandVersion":0,"state":"finished","results":{"type":"table","data":[["learning to rank (ltr), once the domain of academic researchers in machine learning and information retrieval, has begun to make great headway in practical applications on the web. its tools and techniques offer a new way to think about challenges in relevance ranking, personalization, localization, ad targeting and multimedia search, but it shares enough conceptual foundations with traditional search relevance that it?s easy for hands-on engineers to get started with. in this talk, andrew will introduce the field and its key concepts, before diving into one of its best-known algorithms, ranking svm, which adapts support vector machines to ranking tasks instead of classification problems. with real examples taken from work at etsy and elsewhere, he?ll talk about how you can use this algorithm and others like it to incorporate a huge variety of features into your search ranking model: query-specific term weights, implicit user feedback, temporal and geographic data, and even image features. and he?ll touch on applications of ltr beyond traditional search, including ad click prediction and content-based recommendations. no past experience of machine learning will be required. attendees can expect to leave this talk with an understanding of ltr and its applications, and enough insight into ranking svm to enable them to experiment with ranking models on their own data.  "],["modern cars produce data. lots of data. and formula 1 cars produce more than their share. i will present a working demonstration of how modern data streaming can be applied to the data acquisition and analysis problem posed by modern motorsports. instead of bringing multiple formula 1 cars to the talk, i will show how we instrumented a high fidelity physics-based automotive simulator to produce realistic data from simulated cars running on the spa-francorchamps track. we move data from the cars, to the pits, to the engineers back at hq. the result is near real-time visualization and comparison of performance and a great exposition of how to move data using messaging systems like kafka. the code from this talk will be made available as open source.  "],["we observed that marketing teams of major companies tend to build their marketing campaigns based on study of client segmentation and market analysis which can be an heavy workload that directly deteriorate its roi \nusing our client big data (6 000 000 client informations on a hadoop / spark cluster) we tried an other approach to dramaticaly increase the agility for building and tayloring new marketing campaigns. \nwe used test&learn methodolgies to increase the \"uplift\" of the campaigns inspired by the multi-armed bandit problem ( ) and implemented the whole approach in apache spark. \nin this talk we want to share our feedbacks on the approach the success we had and probably more importantly the pitfalls we encountered."],["today's industrial systems produce more and more data everyday. companies are increasingly using big data technologies and data analysis approaches in order to monitor their systems. i will illustrate this trend with a project of predictive maintenance on trains. in cities where millions of people use public transportation everyday, avoiding faults on trains during circulations is critical. the goal of the project is to predict faults on trains in advance so that can be are dispatched to the workshops accordingly, thus avoiding train delays and reducing maintenance costs. i'll explain our approach which uses random forests and artificial neural networks with theano, what are the results and how we measure success, and finally how, from developing models on historical data with python, we progressively moved to production and transposed the models to a distributed environment using spark."],["hubot, github's open source chat bot, is completely revolutionizing how we build, ship and operate software at scale. as a widely distributed company, we rely on online chat as one of our primary communication tools. chatops helps us improve situational awareness during incidents, to share knowledge, to ship software, and much more. we'll look at some concrete examples and talk about the cultural implications embracing chatops has had at github."],["lucene will change the default scoring from tf/idf to bm25 in the next major release. so unless you really enjoy surprises you better learn about it now! tf/idf was easy enough to understand intuitively but how is it with bm25? what do all these parameters do? and what do people mean when they say it is \"probabilistic\"? in this talk i will tell the story of how we came from the probability ranking principle to bm25 with a minimum of math and a maximum of explaining. i will also show how bm25 differs from tf/idf, what it means in practice and give and intuition on what the parameters of this method actually do. you will leave this talk feeling good about lucene changing the default. and of course you will learn many fancy buzzwords to show off with during the breaks."],["there are lots of claims about the benefits of nosql databases, but few realistic demonstrations of the impact that such a database can have on anything more than toy-sized data.  in this talk, i will deconstruct a real-world database schema into the corresponding nosql design. the database that i will use is the musicbrainz database, which exhibits many important idioms found in real databases, such as factoring relations into multiple tables to implement column families, linkage tables, and many-to-one relationships. in spite of such radical structural changes, the resulting denormalized and nested data can still be queried with sql using apache drill, and the queries are often noticeably simpler than the queries used against the original data structures. the methods are practical and easy to apply, and can sometimes be largely automated. for example, i'll show how a percolator pattern can be used to allow the resulting nosql database to be automatically maintained in multiple nosql technologies simultaneously, so that full text search, recommendations, and the hbase api can all be used to access the same data."],["at the beginning of the year 2016, the apache lucene team decided to focus on releasing apache lucene 6. around berlin buzzwords, the new version will be available for testing. this talk will present the new features that lucene 6 will bring: a new data type called \"points\" (also known as dimensional values) and corresponding queries as faster, multidimensional replacement for numericrangequery. it will also completely remove the concept of \"filters\" in favour of non-scoring queries. last but not least, lucene and solr 6 will require java 8 as minimum requirement. this talk will also present the many new features in apache solr 6: it now understands an sql dialect to do queries and aggregations. in combination with a brand new jdbc driver, one can query solr using standard database tools."],["we present a new design pattern for data streaming applications, using apache flink and apache kafka: building applications directly on top of the stream processor, rather than on top of key/value databases populated by data streams. unlike classical setups that use stream processors or libraries to pre-process/aggregate events and update a database with the results, this setup simply gives the role of the database to the stream processor (here apache flink), routing queries to its workers who directly answer them from their internal state computed over the log of events (apache kafka). this architecture pattern has many interesting implications:   - all state updates happen locally in the stream processor. this eliminates the need for (distributed) transactions with an external database, leading to very high performance (we saw cases with >100x speedup compared to pushing the state into a database).   - consistency (exactly-once) is maintained across the entire pipeline: log, stream processor, and application state. that stands in contrast to setups today, where duplicate changes may be pushed to the database, because the database is typically not integrated with the stream processor's consistency mechanism.   - consistency and persistence are realized through distributed snapshots. changes between snapshots are replayed from the input streams or kafka. when snapshots run asynchronously, the overhead of these snapshots is very low   - because application state is part of a streaming program, one can naturally upgrade/rollback the program and state together, replay the stream with a modified program (playing through what-if scenarios) or fork off a new variant of the state (a/b testing)   - this architecture eases the handling of out of order streams and late-arriving events. the stream processor can expose early results in addition to the correct results.   this talk will cover both the high-level introduction to the architecture, the techniques in flink/kafka that make this approach possible, as well as experiences from a large scale setup and technical details."],["\nin this session, you will get your hands on stream processing with apache flink, an open source platform for distributed stream and batch processing. \nwe will introduce flink's datastream api and help you to setup a local development environment to implement and test scalable stream processing programs. \nhands-on coding exercises will make this a fun session to attend. please note: this is a hands-on session. you should be familiar with java or scala and bring a laptop. \nwe recommend to prepare the flink setup by following these instructions ( ) in advance to save some time."]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"_c0","type":"\"string\""}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":null,"error":null,"workflows":[],"startTime":1.465307777097E12,"submitTime":1.465307775529E12,"finishTime":1.465307779295E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"Lowercase","showCommandTitle":true,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"debb4a46-b80d-4fc3-ae55-655ab1cd4e53"},{"version":"CommandV1","origId":2469000391151332,"guid":"bad8976e-b3b9-41c2-8782-c0094d099c39","subtype":"command","commandType":"auto","position":2.828125,"command":"def cleanString(x):\n    return re.sub('\\s+', ' ', re.sub('[^a-zA-Z0-9 ]', '', x)).strip()\nsqlContext.registerFunction('cleanString', cleanString)\n\ndisplay(sql(\"SELECT cleanString(lower(content)) FROM bbuzz_raw WHERE content <> '' LIMIT 10\"))","commandVersion":0,"state":"finished","results":{"type":"table","data":[["learning to rank ltr once the domain of academic researchers in machine learning and information retrieval has begun to make great headway in practical applications on the web its tools and techniques offer a new way to think about challenges in relevance ranking personalization localization ad targeting and multimedia search but it shares enough conceptual foundations with traditional search relevance that its easy for handson engineers to get started with in this talk andrew will introduce the field and its key concepts before diving into one of its bestknown algorithms ranking svm which adapts support vector machines to ranking tasks instead of classification problems with real examples taken from work at etsy and elsewhere hell talk about how you can use this algorithm and others like it to incorporate a huge variety of features into your search ranking model queryspecific term weights implicit user feedback temporal and geographic data and even image features and hell touch on applications of ltr beyond traditional search including ad click prediction and contentbased recommendations no past experience of machine learning will be requiredattendees can expect to leave this talk with an understanding of ltr and its applications and enough insight into ranking svm to enable them to experiment with ranking models on their own data"],["modern cars produce data lots of data and formula 1 cars produce more than their share i will present a working demonstration of how modern data streaming can be applied to the data acquisition and analysis problem posed by modern motorsports instead of bringing multiple formula 1 cars to the talk i will show how we instrumented ahigh fidelityphysicsbased automotive simulator to produce realistic data from simulated cars running on the spafrancorchamps track we movedata from the cars to the pits to the engineers back at hq the result is near realtime visualization and comparison of performance and a great exposition of how to move data using messaging systems like kafka the code from this talk will be made available as open source"],["we observed that marketing teams of major companies tend to build their marketing campaigns based on study of client segmentation and market analysis which can be an heavy workload that directly deteriorate its roi using our client big data 6 000 000 client informations on a hadoop spark cluster we tried an other approach to dramaticaly increase the agility for building and tayloring new marketing campaigns we used testlearn methodolgies to increase the uplift of the campaigns inspired by the multiarmed bandit problem and implemented the whole approach in apache spark in this talk we want to share our feedbacks on the approach the success we had and probably more importantly the pitfalls we encountered"],["todays industrial systems produce more and more data everyday companies are increasingly using big data technologies and data analysis approaches in order to monitor their systems i will illustrate this trend with a project of predictive maintenance on trains in cities where millions of people use public transportation everyday avoiding faults on trains during circulations is critical the goal of the project is to predict faults on trains in advance so that can be are dispatched to the workshops accordingly thus avoiding train delays and reducing maintenance costs ill explain our approach which uses random forests and artificial neural networks with theano what are the results and how we measure success and finally how from developing models on historical data with python we progressively moved to production and transposed the models to a distributed environment using spark"],["hubot githubs open source chat bot is completely revolutionizing how we build ship and operate software at scale as a widely distributed company we rely on online chat as one of our primary communication tools chatops helps us improve situational awareness during incidents to share knowledge to ship software and much more well look at some concrete examples and talk about the cultural implications embracing chatops has had at github"],["lucene will change the default scoring from tfidf to bm25 in the next major release so unless you really enjoy surprises you better learn about it now tfidf was easy enough to understand intuitively but how is it with bm25 what do all these parameters do and what do people mean when they say it is probabilistic in this talk i will tell the story of how we came from the probability ranking principle to bm25 with a minimum of math and a maximum of explaining i will also show how bm25 differs from tfidf what it means in practice and give and intuition on what the parameters of this method actually do you will leave this talk feeling good about lucene changing the default and of course you will learn many fancy buzzwords to show off with during the breaks"],["there are lots of claims about the benefits of nosql databases but few realistic demonstrations of the impact that such a database can have on anything more than toysized data in this talk i will deconstruct a realworld database schema into the corresponding nosql design the database that i will use is the musicbrainz database which exhibits many important idioms found in real databases such as factoring relations into multiple tables to implement column families linkage tables and manytoone relationships in spite of such radical structural changes the resulting denormalized and nested data can still be queried with sql using apache drill and the queries are often noticeably simpler than the queries used against the original data structures the methods are practical and easy to apply and can sometimes be largely automated for example ill show how a percolator pattern can be used to allow the resulting nosql database to be automatically maintained in multiple nosql technologies simultaneously so that full text search recommendations and the hbase api can all be used to access the same data"],["at the beginning of the year 2016 the apache lucene team decided to focus on releasing apache lucene 6 around berlin buzzwords the new version will be available for testing this talk will present the new features that lucene 6 will bring a new data type called points also known as dimensional valuesand corresponding queries as faster multidimensional replacement for numericrangequery it will alsocompletely remove the concept of filters in favour ofnonscoring queries last but not least lucene and solr 6 will requirejava 8 as minimum requirement this talk will also present the many new features in apache solr 6 it now understands an sql dialect to do queries and aggregations in combination with a brand new jdbc driver one can query solr using standard database tools"],["we present a new design pattern for data streaming applications using apache flink and apache kafka building applications directly on top of the stream processor rather than on top of keyvalue databases populated by data streams unlike classical setups that use stream processors or libraries to preprocessaggregate events and update a database with the results this setup simply gives the role of the database to the stream processor here apache flink routing queries to its workers who directly answer them from their internal state computed over the log of events apache kafka this architecture pattern has many interesting implications all state updates happen locally in the stream processor this eliminates the need for distributed transactions with an external database leading to very high performance we saw cases with 100x speedup compared to pushing the state into a database consistency exactlyonce is maintained across the entire pipeline log stream processor and application state that stands in contrast to setups today where duplicate changes may be pushed to the database because the database is typically not integrated with the stream processors consistency mechanism consistency and persistence are realized through distributed snapshots changes between snapshots are replayed from the input streams or kafka when snapshots run asynchronously the overhead of these snapshots is very low because application state is part of a streaming program one can naturally upgraderollback the program and state together replay the stream with a modified program playing through whatif scenarios or fork off a new variant of the state ab testing this architecture eases the handling of out of order streams and latearriving events the stream processor can expose early results in addition to the correct results this talk will cover both the highlevel introduction to the architecture the techniques in flinkkafka that make this approach possible as well as experiences from a large scale setup and technical details"],["in this session you will get your hands on stream processing with apache flink an open source platform for distributed stream and batch processing we will introduce flinks datastream api and help you to setup a local development environment to implement and test scalable stream processing programs handson coding exercises will make this a fun session to attend please note this is a handson session you should be familiar with java or scala and bring a laptop we recommend to prepare the flink setup by following these instructions in advance to save some time"]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"_c0","type":"\"string\""}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":null,"error":null,"workflows":[],"startTime":1.465307788452E12,"submitTime":1.465307789603E12,"finishTime":1.46530779063E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"String Cleaning (Remove Special Characters)","showCommandTitle":true,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"2fa98d3d-8425-492a-812e-b90d99da8512"},{"version":"CommandV1","origId":2469000391151334,"guid":"6fa240c8-3aed-4b79-9af3-5de020ffb518","subtype":"command","commandType":"auto","position":2.86328125,"command":"stopwords = set(sc.textFile(\"dbfs:/mnt/bbuzz2016/stopwords.txt\").collect())\ndef removeStopwords(x):\n    return ' '.join([word for word in x.split(' ') if word not in stopwords])\nsqlContext.registerFunction('removeStopwords', removeStopwords)\n#stopwords\n#display(sqlContext.sql(\"SELECT removeStopwords(cleanString(lower(content))) FROM bbuzz_raw WHERE content <> '' LIMIT 10\"))\n# -> See https://issues.apache.org/jira/browse/SPARK-11159\n\nsqlContext.registerFunction('clearAll', lambda x: removeStopwords(cleanString(x)))\ndisplay(sql(\"SELECT clearAll(lower(content)) FROM bbuzz_raw WHERE content <> '' LIMIT 10\"))","commandVersion":0,"state":"finished","results":{"type":"table","data":[["learning rank ltr domain academic researchers machine learning information retrieval begun make great headway practical applications web tools techniques offer new way think challenges relevance ranking personalization localization ad targeting multimedia search shares enough conceptual foundations traditional search relevance easy handson engineers get started talk andrew introduce field key concepts diving one bestknown algorithms ranking svm adapts support vector machines ranking tasks instead classification problems real examples taken work etsy elsewhere hell talk use algorithm others like incorporate huge variety features search ranking model queryspecific term weights implicit user feedback temporal geographic data even image features hell touch applications ltr beyond traditional search including ad click prediction contentbased recommendations past experience machine learning requiredattendees expect leave talk understanding ltr applications enough insight ranking svm enable experiment ranking models data"],["modern cars produce data lots data formula 1 cars produce share present working demonstration modern data streaming applied data acquisition analysis problem posed modern motorsports instead bringing multiple formula 1 cars talk show instrumented ahigh fidelityphysicsbased automotive simulator produce realistic data simulated cars running spafrancorchamps track movedata cars pits engineers back hq result near realtime visualization comparison performance great exposition move data using messaging systems like kafka code talk made available open source"],["observed marketing teams major companies tend build marketing campaigns based study client segmentation market analysis heavy workload directly deteriorate roi using client big data 6 000 000 client informations hadoop spark cluster tried approach dramaticaly increase agility building tayloring new marketing campaigns used testlearn methodolgies increase uplift campaigns inspired multiarmed bandit problem implemented whole approach apache spark talk want share feedbacks approach success probably importantly pitfalls encountered"],["todays industrial systems produce data everyday companies increasingly using big data technologies data analysis approaches order monitor systems illustrate trend project predictive maintenance trains cities millions people use public transportation everyday avoiding faults trains circulations critical goal project predict faults trains advance dispatched workshops accordingly thus avoiding train delays reducing maintenance costs ill explain approach uses random forests artificial neural networks theano results measure success finally developing models historical data python progressively moved production transposed models distributed environment using spark"],["hubot githubs open source chat bot completely revolutionizing build ship operate software scale widely distributed company rely online chat one primary communication tools chatops helps us improve situational awareness incidents share knowledge ship software much well look concrete examples talk cultural implications embracing chatops github"],["lucene change default scoring tfidf bm25 next major release unless really enjoy surprises better learn tfidf easy enough understand intuitively bm25 parameters people mean say probabilistic talk tell story came probability ranking principle bm25 minimum math maximum explaining also show bm25 differs tfidf means practice give intuition parameters method actually leave talk feeling good lucene changing default course learn many fancy buzzwords show breaks"],["lots claims benefits nosql databases realistic demonstrations impact database anything toysized data talk deconstruct realworld database schema corresponding nosql design database use musicbrainz database exhibits many important idioms found real databases factoring relations multiple tables implement column families linkage tables manytoone relationships spite radical structural changes resulting denormalized nested data still queried sql using apache drill queries often noticeably simpler queries used original data structures methods practical easy apply sometimes largely automated example ill show percolator pattern used allow resulting nosql database automatically maintained multiple nosql technologies simultaneously full text search recommendations hbase api used access data"],["beginning year 2016 apache lucene team decided focus releasing apache lucene 6 around berlin buzzwords new version available testing talk present new features lucene 6 bring new data type called points also known dimensional valuesand corresponding queries faster multidimensional replacement numericrangequery alsocompletely remove concept filters favour ofnonscoring queries last least lucene solr 6 requirejava 8 minimum requirement talk also present many new features apache solr 6 understands sql dialect queries aggregations combination brand new jdbc driver one query solr using standard database tools"],["present new design pattern data streaming applications using apache flink apache kafka building applications directly top stream processor rather top keyvalue databases populated data streams unlike classical setups use stream processors libraries preprocessaggregate events update database results setup simply gives role database stream processor apache flink routing queries workers directly answer internal state computed log events apache kafka architecture pattern many interesting implications state updates happen locally stream processor eliminates need distributed transactions external database leading high performance saw cases 100x speedup compared pushing state database consistency exactlyonce maintained across entire pipeline log stream processor application state stands contrast setups today duplicate changes may pushed database database typically integrated stream processors consistency mechanism consistency persistence realized distributed snapshots changes snapshots replayed input streams kafka snapshots run asynchronously overhead snapshots low application state part streaming program one naturally upgraderollback program state together replay stream modified program playing whatif scenarios fork new variant state ab testing architecture eases handling order streams latearriving events stream processor expose early results addition correct results talk cover highlevel introduction architecture techniques flinkkafka make approach possible well experiences large scale setup technical details"],["session get hands stream processing apache flink open source platform distributed stream batch processing introduce flinks datastream api help setup local development environment implement test scalable stream processing programs handson coding exercises make fun session attend please note handson session familiar java scala bring laptop recommend prepare flink setup following instructions advance save time"]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"_c0","type":"\"string\""}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":null,"error":null,"workflows":[],"startTime":1.465307796245E12,"submitTime":1.465307797386E12,"finishTime":1.465307801348E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"Remove Stopwords","showCommandTitle":true,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"8e9f73d2-49d0-4ba1-9cf7-f76294e8e257"},{"version":"CommandV1","origId":2469000391151335,"guid":"60b2ab26-654f-4c1a-8fb1-705c4a272de5","subtype":"command","commandType":"auto","position":2.869140625,"command":"# Cooler: http://www.nltk.org/index.html\n#wnl = WordNetLemmatizer()\n#wnl.lemmatize(x)\n# Alternatives:\n# * http://nlp.stanford.edu/software/\n# * https://opennlp.apache.org/ \ndef lemmatize(x):\n    return ' '.join([re.sub('s$', '', word) for word in x.split(' ')])\nsqlContext.registerFunction('lemmatize', lemmatize)\n\nsqlContext.registerFunction('clearAll', lambda x: lemmatize(removeStopwords(cleanString(x))))\ndisplay(sql(\"SELECT clearAll(lower(content)) FROM bbuzz_raw WHERE content <> '' LIMIT 10\"))","commandVersion":0,"state":"finished","results":{"type":"table","data":[["learning rank ltr domain academic researcher machine learning information retrieval begun make great headway practical application web tool technique offer new way think challenge relevance ranking personalization localization ad targeting multimedia search share enough conceptual foundation traditional search relevance easy handson engineer get started talk andrew introduce field key concept diving one bestknown algorithm ranking svm adapt support vector machine ranking task instead classification problem real example taken work etsy elsewhere hell talk use algorithm other like incorporate huge variety feature search ranking model queryspecific term weight implicit user feedback temporal geographic data even image feature hell touch application ltr beyond traditional search including ad click prediction contentbased recommendation past experience machine learning requiredattendee expect leave talk understanding ltr application enough insight ranking svm enable experiment ranking model data"],["modern car produce data lot data formula 1 car produce share present working demonstration modern data streaming applied data acquisition analysi problem posed modern motorsport instead bringing multiple formula 1 car talk show instrumented ahigh fidelityphysicsbased automotive simulator produce realistic data simulated car running spafrancorchamp track movedata car pit engineer back hq result near realtime visualization comparison performance great exposition move data using messaging system like kafka code talk made available open source"],["observed marketing team major companie tend build marketing campaign based study client segmentation market analysi heavy workload directly deteriorate roi using client big data 6 000 000 client information hadoop spark cluster tried approach dramaticaly increase agility building tayloring new marketing campaign used testlearn methodolgie increase uplift campaign inspired multiarmed bandit problem implemented whole approach apache spark talk want share feedback approach succes probably importantly pitfall encountered"],["today industrial system produce data everyday companie increasingly using big data technologie data analysi approache order monitor system illustrate trend project predictive maintenance train citie million people use public transportation everyday avoiding fault train circulation critical goal project predict fault train advance dispatched workshop accordingly thu avoiding train delay reducing maintenance cost ill explain approach use random forest artificial neural network theano result measure succes finally developing model historical data python progressively moved production transposed model distributed environment using spark"],["hubot github open source chat bot completely revolutionizing build ship operate software scale widely distributed company rely online chat one primary communication tool chatop help u improve situational awarenes incident share knowledge ship software much well look concrete example talk cultural implication embracing chatop github"],["lucene change default scoring tfidf bm25 next major release unles really enjoy surprise better learn tfidf easy enough understand intuitively bm25 parameter people mean say probabilistic talk tell story came probability ranking principle bm25 minimum math maximum explaining also show bm25 differ tfidf mean practice give intuition parameter method actually leave talk feeling good lucene changing default course learn many fancy buzzword show break"],["lot claim benefit nosql database realistic demonstration impact database anything toysized data talk deconstruct realworld database schema corresponding nosql design database use musicbrainz database exhibit many important idiom found real database factoring relation multiple table implement column familie linkage table manytoone relationship spite radical structural change resulting denormalized nested data still queried sql using apache drill querie often noticeably simpler querie used original data structure method practical easy apply sometime largely automated example ill show percolator pattern used allow resulting nosql database automatically maintained multiple nosql technologie simultaneously full text search recommendation hbase api used acces data"],["beginning year 2016 apache lucene team decided focu releasing apache lucene 6 around berlin buzzword new version available testing talk present new feature lucene 6 bring new data type called point also known dimensional valuesand corresponding querie faster multidimensional replacement numericrangequery alsocompletely remove concept filter favour ofnonscoring querie last least lucene solr 6 requirejava 8 minimum requirement talk also present many new feature apache solr 6 understand sql dialect querie aggregation combination brand new jdbc driver one query solr using standard database tool"],["present new design pattern data streaming application using apache flink apache kafka building application directly top stream processor rather top keyvalue database populated data stream unlike classical setup use stream processor librarie preprocessaggregate event update database result setup simply give role database stream processor apache flink routing querie worker directly answer internal state computed log event apache kafka architecture pattern many interesting implication state update happen locally stream processor eliminate need distributed transaction external database leading high performance saw case 100x speedup compared pushing state database consistency exactlyonce maintained acros entire pipeline log stream processor application state stand contrast setup today duplicate change may pushed database database typically integrated stream processor consistency mechanism consistency persistence realized distributed snapshot change snapshot replayed input stream kafka snapshot run asynchronously overhead snapshot low application state part streaming program one naturally upgraderollback program state together replay stream modified program playing whatif scenario fork new variant state ab testing architecture ease handling order stream latearriving event stream processor expose early result addition correct result talk cover highlevel introduction architecture technique flinkkafka make approach possible well experience large scale setup technical detail"],["session get hand stream processing apache flink open source platform distributed stream batch processing introduce flink datastream api help setup local development environment implement test scalable stream processing program handson coding exercise make fun session attend please note handson session familiar java scala bring laptop recommend prepare flink setup following instruction advance save time"]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"_c0","type":"\"string\""}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":null,"error":null,"workflows":[],"startTime":1.465307803107E12,"submitTime":1.465307804243E12,"finishTime":1.465307805534E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"Lemmatize (unsophisticated)","showCommandTitle":true,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"02887a39-ac30-4844-b987-90289e320a44"},{"version":"CommandV1","origId":2469000391151336,"guid":"4ff6fdb8-4c20-4263-9b10-ca90de9302f8","subtype":"command","commandType":"auto","position":2.8720703125,"command":"pairs = [\n  'big data',\n  'open source',\n  'machine learning',\n  'real time',\n  'berlin buzzword',\n  'search engine',\n  'data store',\n  'event sourcing',\n  'map reduce'\n]\ndef tokenize(x):\n    for pair in pairs:\n        x = x.replace(pair, pair.replace(' ', ''))\n    return x\nsqlContext.registerFunction('tokenize', tokenize)\n\nsqlContext.registerFunction('clearAll', lambda x: tokenize(lemmatize(removeStopwords(cleanString(x)))))\ndisplay(sql(\"SELECT clearAll(lower(content)) FROM bbuzz_raw WHERE content <> '' LIMIT 10\"))","commandVersion":0,"state":"finished","results":{"type":"table","data":[["learning rank ltr domain academic researcher machinelearning information retrieval begun make great headway practical application web tool technique offer new way think challenge relevance ranking personalization localization ad targeting multimedia search share enough conceptual foundation traditional search relevance easy handson engineer get started talk andrew introduce field key concept diving one bestknown algorithm ranking svm adapt support vector machine ranking task instead classification problem real example taken work etsy elsewhere hell talk use algorithm other like incorporate huge variety feature search ranking model queryspecific term weight implicit user feedback temporal geographic data even image feature hell touch application ltr beyond traditional search including ad click prediction contentbased recommendation past experience machinelearning requiredattendee expect leave talk understanding ltr application enough insight ranking svm enable experiment ranking model data"],["modern car produce data lot data formula 1 car produce share present working demonstration modern data streaming applied data acquisition analysi problem posed modern motorsport instead bringing multiple formula 1 car talk show instrumented ahigh fidelityphysicsbased automotive simulator produce realistic data simulated car running spafrancorchamp track movedata car pit engineer back hq result near realtime visualization comparison performance great exposition move data using messaging system like kafka code talk made available opensource"],["observed marketing team major companie tend build marketing campaign based study client segmentation market analysi heavy workload directly deteriorate roi using client bigdata 6 000 000 client information hadoop spark cluster tried approach dramaticaly increase agility building tayloring new marketing campaign used testlearn methodolgie increase uplift campaign inspired multiarmed bandit problem implemented whole approach apache spark talk want share feedback approach succes probably importantly pitfall encountered"],["today industrial system produce data everyday companie increasingly using bigdata technologie data analysi approache order monitor system illustrate trend project predictive maintenance train citie million people use public transportation everyday avoiding fault train circulation critical goal project predict fault train advance dispatched workshop accordingly thu avoiding train delay reducing maintenance cost ill explain approach use random forest artificial neural network theano result measure succes finally developing model historical data python progressively moved production transposed model distributed environment using spark"],["hubot github opensource chat bot completely revolutionizing build ship operate software scale widely distributed company rely online chat one primary communication tool chatop help u improve situational awarenes incident share knowledge ship software much well look concrete example talk cultural implication embracing chatop github"],["lucene change default scoring tfidf bm25 next major release unles really enjoy surprise better learn tfidf easy enough understand intuitively bm25 parameter people mean say probabilistic talk tell story came probability ranking principle bm25 minimum math maximum explaining also show bm25 differ tfidf mean practice give intuition parameter method actually leave talk feeling good lucene changing default course learn many fancy buzzword show break"],["lot claim benefit nosql database realistic demonstration impact database anything toysized data talk deconstruct realworld database schema corresponding nosql design database use musicbrainz database exhibit many important idiom found real database factoring relation multiple table implement column familie linkage table manytoone relationship spite radical structural change resulting denormalized nested data still queried sql using apache drill querie often noticeably simpler querie used original data structure method practical easy apply sometime largely automated example ill show percolator pattern used allow resulting nosql database automatically maintained multiple nosql technologie simultaneously full text search recommendation hbase api used acces data"],["beginning year 2016 apache lucene team decided focu releasing apache lucene 6 around berlinbuzzword new version available testing talk present new feature lucene 6 bring new data type called point also known dimensional valuesand corresponding querie faster multidimensional replacement numericrangequery alsocompletely remove concept filter favour ofnonscoring querie last least lucene solr 6 requirejava 8 minimum requirement talk also present many new feature apache solr 6 understand sql dialect querie aggregation combination brand new jdbc driver one query solr using standard database tool"],["present new design pattern data streaming application using apache flink apache kafka building application directly top stream processor rather top keyvalue database populated data stream unlike classical setup use stream processor librarie preprocessaggregate event update database result setup simply give role database stream processor apache flink routing querie worker directly answer internal state computed log event apache kafka architecture pattern many interesting implication state update happen locally stream processor eliminate need distributed transaction external database leading high performance saw case 100x speedup compared pushing state database consistency exactlyonce maintained acros entire pipeline log stream processor application state stand contrast setup today duplicate change may pushed database database typically integrated stream processor consistency mechanism consistency persistence realized distributed snapshot change snapshot replayed input stream kafka snapshot run asynchronously overhead snapshot low application state part streaming program one naturally upgraderollback program state together replay stream modified program playing whatif scenario fork new variant state ab testing architecture ease handling order stream latearriving event stream processor expose early result addition correct result talk cover highlevel introduction architecture technique flinkkafka make approach possible well experience large scale setup technical detail"],["session get hand stream processing apache flink opensource platform distributed stream batch processing introduce flink datastream api help setup local development environment implement test scalable stream processing program handson coding exercise make fun session attend please note handson session familiar java scala bring laptop recommend prepare flink setup following instruction advance save time"]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"_c0","type":"\"string\""}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":null,"error":null,"workflows":[],"startTime":1.465307807944E12,"submitTime":1.465307809084E12,"finishTime":1.465307810245E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"Tokenize (very unsophisticated)","showCommandTitle":true,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"a5bd4ce8-ddc3-4da0-bbf8-34d6d4f68315"},{"version":"CommandV1","origId":2469000391151337,"guid":"5279538a-8697-4bf7-9404-a3bb5dd5fc5b","subtype":"command","commandType":"auto","position":2.87353515625,"command":"display(sql(\"SELECT link FROM bbuzz_raw WHERE content <> '' LIMIT 10\"))","commandVersion":0,"state":"finished","results":{"type":"table","data":[["https://www.berlinbuzzwords.de/session/learning-rank-where-search-meets-machine-learning"],["https://www.berlinbuzzwords.de/session/fast-cars-big-data-how-streaming-can-help-formula-1"],["https://www.berlinbuzzwords.de/session/project-use-case-improve-your-marketing-reach-using-large-scale-machine-learning-spark"],["https://www.berlinbuzzwords.de/session/predictive-maintenance-poc-production-spark"],["https://www.berlinbuzzwords.de/session/shipping-scale-chatops-github"],["https://www.berlinbuzzwords.de/session/bm25-demystified"],["https://www.berlinbuzzwords.de/session/real-world-nosql-schema-design"],["https://www.berlinbuzzwords.de/session/apache-lucene-6-whats-coming-next"],["https://www.berlinbuzzwords.de/session/stream-processor-database-building-online-applications-directly-streams-apache-flink-and"],["https://www.berlinbuzzwords.de/session/getting-started-stream-processing-apache-flink"]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"link","type":"\"string\""}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":null,"error":null,"workflows":[],"startTime":1.465307814288E12,"submitTime":1.465307815429E12,"finishTime":1.465307816255E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"b5026845-98c0-4459-959c-6cead4cca42e"},{"version":"CommandV1","origId":2469000391151339,"guid":"93c115b9-cd3e-4eb5-b149-d5d6cc6d44eb","subtype":"command","commandType":"auto","position":2.8739013671875,"command":"display(sql(\"SELECT regexp_extract(regexp_replace(link, 'www\\.berlinbuzzwords\\.de', '2016.berlinbuzzwords.de'), '([0-9]+)\\.berlinbuzzwords', 1), link FROM bbuzz_raw WHERE content <> '' LIMIT 10\"))","commandVersion":0,"state":"finished","results":{"type":"table","data":[["2016","https://www.berlinbuzzwords.de/session/learning-rank-where-search-meets-machine-learning"],["2016","https://www.berlinbuzzwords.de/session/fast-cars-big-data-how-streaming-can-help-formula-1"],["2016","https://www.berlinbuzzwords.de/session/project-use-case-improve-your-marketing-reach-using-large-scale-machine-learning-spark"],["2016","https://www.berlinbuzzwords.de/session/predictive-maintenance-poc-production-spark"],["2016","https://www.berlinbuzzwords.de/session/shipping-scale-chatops-github"],["2016","https://www.berlinbuzzwords.de/session/bm25-demystified"],["2016","https://www.berlinbuzzwords.de/session/real-world-nosql-schema-design"],["2016","https://www.berlinbuzzwords.de/session/apache-lucene-6-whats-coming-next"],["2016","https://www.berlinbuzzwords.de/session/stream-processor-database-building-online-applications-directly-streams-apache-flink-and"],["2016","https://www.berlinbuzzwords.de/session/getting-started-stream-processing-apache-flink"]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"_c0","type":"\"string\""},{"name":"link","type":"\"string\""}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":null,"error":null,"workflows":[],"startTime":1.465307872358E12,"submitTime":1.465307873516E12,"finishTime":1.465307874304E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"8986bd52-6ee6-44c8-b5de-af321aa12319"},{"version":"CommandV1","origId":183210672370547,"guid":"20c64e52-c142-460b-a567-a5fc047e891c","subtype":"command","commandType":"auto","position":2.875,"command":"bbuzz_websites = sqlContext.sql(\"\"\"\nSELECT\n  link,\n  speakers,\n  regexp_extract(regexp_replace(link, 'www\\.berlinbuzzwords\\.de', '2016.berlinbuzzwords.de'), '([0-9]+)\\.berlinbuzzwords', 1) as year,\n  cleanString(lower(title)) as title,\n  cleanString(lower(content)) as content,\n  clearAll(lower(concat(title, ' ', content))) as body\nFROM bbuzz_raw\n\"\"\")\nbbuzz_websites.registerTempTable(\"bbuzz_websites\")\ndisplay(sql(\"SELECT * FROM bbuzz_websites LIMIT 10\"))","commandVersion":0,"state":"finished","results":{"type":"table","data":[["https://www.berlinbuzzwords.de/users/andrew-clegg",[],"2016","andrew clegg","","andrew clegg"],["https://www.berlinbuzzwords.de/users/georgi-knox",[],"2016","georgi knox","","georgi knox"],["https://www.berlinbuzzwords.de/users/heloise-nonne",[],"2016","heloise nonne","","heloise nonne"],["https://www.berlinbuzzwords.de/users/ted-dunning",[],"2016","ted dunning","","ted dunning"],["https://www.berlinbuzzwords.de/users/matthieu-vautrot",[],"2016","matthieu vautrot","","matthieu vautrot"],["https://www.berlinbuzzwords.de/session/learning-rank-where-search-meets-machine-learning",["andrew clegg"],"2016","learning to rank where search meets machine learning","learning to rank ltr once the domain of academic researchers in machine learning and information retrieval has begun to make great headway in practical applications on the web its tools and techniques offer a new way to think about challenges in relevance ranking personalization localization ad targeting and multimedia search but it shares enough conceptual foundations with traditional search relevance that its easy for handson engineers to get started with in this talk andrew will introduce the field and its key concepts before diving into one of its bestknown algorithms ranking svm which adapts support vector machines to ranking tasks instead of classification problems with real examples taken from work at etsy and elsewhere hell talk about how you can use this algorithm and others like it to incorporate a huge variety of features into your search ranking model queryspecific term weights implicit user feedback temporal and geographic data and even image features and hell touch on applications of ltr beyond traditional search including ad click prediction and contentbased recommendations no past experience of machine learning will be requiredattendees can expect to leave this talk with an understanding of ltr and its applications and enough insight into ranking svm to enable them to experiment with ranking models on their own data","learning rank search meet machinelearning learning rank ltr domain academic researcher machinelearning information retrieval begun make great headway practical application web tool technique offer new way think challenge relevance ranking personalization localization ad targeting multimedia search share enough conceptual foundation traditional search relevance easy handson engineer get started talk andrew introduce field key concept diving one bestknown algorithm ranking svm adapt support vector machine ranking task instead classification problem real example taken work etsy elsewhere hell talk use algorithm other like incorporate huge variety feature search ranking model queryspecific term weight implicit user feedback temporal geographic data even image feature hell touch application ltr beyond traditional search including ad click prediction contentbased recommendation past experience machinelearning requiredattendee expect leave talk understanding ltr application enough insight ranking svm enable experiment ranking model data"],["https://www.berlinbuzzwords.de/users/roman-shaposhnik",[],"2016","roman shaposhnik","","roman shaposhnik"],["https://www.berlinbuzzwords.de/session/fast-cars-big-data-how-streaming-can-help-formula-1",["ted dunning"],"2016","fast cars big data how streaming can help formula 1","modern cars produce data lots of data and formula 1 cars produce more than their share i will present a working demonstration of how modern data streaming can be applied to the data acquisition and analysis problem posed by modern motorsports instead of bringing multiple formula 1 cars to the talk i will show how we instrumented ahigh fidelityphysicsbased automotive simulator to produce realistic data from simulated cars running on the spafrancorchamps track we movedata from the cars to the pits to the engineers back at hq the result is near realtime visualization and comparison of performance and a great exposition of how to move data using messaging systems like kafka the code from this talk will be made available as open source","fast car bigdata streaming help formula 1 modern car produce data lot data formula 1 car produce share present working demonstration modern data streaming applied data acquisition analysi problem posed modern motorsport instead bringing multiple formula 1 car talk show instrumented ahigh fidelityphysicsbased automotive simulator produce realistic data simulated car running spafrancorchamp track movedata car pit engineer back hq result near realtime visualization comparison performance great exposition move data using messaging system like kafka code talk made available opensource"],["https://www.berlinbuzzwords.de/session/project-use-case-improve-your-marketing-reach-using-large-scale-machine-learning-spark",["nina bertrand","matthieu vautrot"],"2016","project use case improve your marketing reach using large scale machine learning on spark","we observed that marketing teams of major companies tend to build their marketing campaigns based on study of client segmentation and market analysis which can be an heavy workload that directly deteriorate its roi using our client big data 6 000 000 client informations on a hadoop spark cluster we tried an other approach to dramaticaly increase the agility for building and tayloring new marketing campaigns we used testlearn methodolgies to increase the uplift of the campaigns inspired by the multiarmed bandit problem and implemented the whole approach in apache spark in this talk we want to share our feedbacks on the approach the success we had and probably more importantly the pitfalls we encountered","project use case improve marketing reach using large scale machinelearning spark observed marketing team major companie tend build marketing campaign based study client segmentation market analysi heavy workload directly deteriorate roi using client bigdata 6 000 000 client information hadoop spark cluster tried approach dramaticaly increase agility building tayloring new marketing campaign used testlearn methodolgie increase uplift campaign inspired multiarmed bandit problem implemented whole approach apache spark talk want share feedback approach succes probably importantly pitfall encountered"],["https://www.berlinbuzzwords.de/users/nina-bertrand",[],"2016","nina bertrand","","nina bertrand"]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"link","type":"\"string\""},{"name":"speakers","type":"{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"},{"name":"year","type":"\"string\""},{"name":"title","type":"\"string\""},{"name":"content","type":"\"string\""},{"name":"body","type":"\"string\""}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":null,"error":null,"workflows":[],"startTime":1.465307877528E12,"submitTime":1.465307878673E12,"finishTime":1.465307879704E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"45aabc34-a903-430c-9a6c-c744562095d2"},{"version":"CommandV1","origId":183210672370548,"guid":"bbdae019-1a30-4ca9-9bbe-453d1b8cfcd1","subtype":"command","commandType":"auto","position":2.9765625,"command":"sessions = sqlContext.sql(\"\"\"\n  SELECT * FROM bbuzz_websites\n  WHERE\n    (link LIKE '%.de/content%' OR link LIKE '%.de/session%')\n    AND NOT (title LIKE 'lunch%' OR title LIKE 'coffee break%' OR title LIKE 'lightning talk%' OR title LIKE '% hackathon' OR title LIKE '% workshop' OR title LIKE '% barcamp')\n\"\"\")\nsessions.registerTempTable(\"sessions\")\ndisplay(sql(\"SELECT link, title FROM sessions WHERE year = 2015\"))","commandVersion":0,"state":"finished","results":{"type":"table","data":[["http://2015.berlinbuzzwords.de/session/low-latency-scalable-web-crawling-apache-storm","low latency scalable web crawling on apache storm"],["http://2015.berlinbuzzwords.de/session/hive-spark","hive on spark"],["http://2015.berlinbuzzwords.de/session/scale-nsq-realtime-distributed-messaging-platform","scale with nsq a realtime distributed messaging platform"],["http://2015.berlinbuzzwords.de/session/change-data-capture-magic-wand-we-forgot","change data capture the magic wand we forgot"],["http://2015.berlinbuzzwords.de/session/using-random-projections-make-sense-high-dimensional-big-data","using random projections to make sense of highdimensional big data"],["http://2015.berlinbuzzwords.de/session/application-performance-management-open-source-tools","application performance management with open source tools"],["http://2015.berlinbuzzwords.de/session/diving-elasticsearch-discovery","diving into elasticsearch discovery"],["http://2015.berlinbuzzwords.de/session/fast-decompression-lucene-codec","fast decompression lucene codec"],["http://2015.berlinbuzzwords.de/session/real-time-analytics-apache-cassandra-and-apache-spark","real time analytics with apache cassandra and apache spark"],["http://2015.berlinbuzzwords.de/session/apache-flink-deep-dive","apache flink deepdive"],["http://2015.berlinbuzzwords.de/session/detecting-events-web-java-kafka-and-zookeeper","detecting events on the web with java kafka and zookeeper"],["http://2015.berlinbuzzwords.de/session/real-time-big-data-analytics-kafka-storm-hbase","real time big data analytics with kafka storm hbase"],["http://2015.berlinbuzzwords.de/session/signatures-patterns-and-trends-timeseries-data-mining-etsy","signatures patterns and trends timeseries data mining at etsy"],["http://2015.berlinbuzzwords.de/session/cassandra-yammer","cassandra at yammer"],["http://2015.berlinbuzzwords.de/session/approaching-join-index-lucene","approaching join index for lucene"],["http://2015.berlinbuzzwords.de/session/youve-got-questions-weve-got-answers","youve got questions weve got answers"],["http://2015.berlinbuzzwords.de/session/side-side-elasticsearch-solr-part-2-performance-scalability","side by side with elasticsearch solr part 2 performance scalability"],["http://2015.berlinbuzzwords.de/session/real-time-monitoring-distributed-systems","realtime monitoring of distributed systems"],["http://2015.berlinbuzzwords.de/session/introduction-apache-kylin-business-intelligence-meets-big-data","an introduction to apache kylin business intelligence meets big data"],["http://2015.berlinbuzzwords.de/session/beyond-significant-terms","beyond significant terms"],["http://2015.berlinbuzzwords.de/session/memory-data-pipeline-and-warehouse-scale-using-spark-spark-sql-tachyon-and-parquet","inmemory data pipeline and warehouse at scale using spark spark sql tachyon and parquet"],["http://2015.berlinbuzzwords.de/session/designing-nrtnearrealtime-stream-processing-systems-using-storm","designing nrtnearrealtime stream processing systems using storm"],["http://2015.berlinbuzzwords.de/session/computing-recommendations-extreme-scale-apache-flink","computing recommendations at extreme scale with apache flink"],["http://2015.berlinbuzzwords.de/session/dos-and-donts-elasticsearch-scalability-and-performance","the dos and donts of elasticsearch scalability and performance"],["http://2015.berlinbuzzwords.de/session/apache-lucene-5-new-features-and-improvements-apache-solr-and-elasticsearch","apache lucene 5 new features and improvements for apache solr and elasticsearch"],["http://2015.berlinbuzzwords.de/session/understanding-databases-distributed-docker-applications","understanding databases for distributed docker applications"],["http://2015.berlinbuzzwords.de/session/whats-news-or-why-angela-merkel-not-significant","whats in the news or why angela merkel is not significant"],["http://2015.berlinbuzzwords.de/session/going-deep-spark-streaming","going deep with spark streaming"],["http://2015.berlinbuzzwords.de/session/designing-concurrent-distributed-sequence-numbers-elasticsearch","designing concurrent distributed sequence numbers for elasticsearch"],["http://2015.berlinbuzzwords.de/session/machine-learning-startup-big-data-company","from machine learning startup to big data company"],["http://2015.berlinbuzzwords.de/session/data-challenges-3d-computer-vision","data challenges with 3d computer vision"],["http://2015.berlinbuzzwords.de/session/compression-lucene","compression in lucene"],["http://2015.berlinbuzzwords.de/session/algorithms-and-data-structures-power-lucene-and-elasticsearch","algorithms and datastructures that power lucene and elasticsearch"],["http://2015.berlinbuzzwords.de/session/practical-t-digest-applications","practical tdigest applications"],["http://2015.berlinbuzzwords.de/session/talk-talk-how-communicate-non-coder","talk the talk how to communicate with the noncoder"],["http://2015.berlinbuzzwords.de/session/building-data-pipelines-simple-more-advanced-hands-experience","building data pipelines from simple to more advanced handson experience"],["http://2015.berlinbuzzwords.de/session/solr-sparse-faceting","solr sparse faceting"],["http://2015.berlinbuzzwords.de/session/predictive-insights-it-operations","predictive insights for it operations"],["http://2015.berlinbuzzwords.de/session/whats-1s-and-0s-making-sense-binary-data-scale-0","whats with the 1s and 0s making sense of binary data at scale"],["http://2015.berlinbuzzwords.de/session/complete-tweet-index-apache-lucene","a complete tweet index on apache lucene"],["http://2015.berlinbuzzwords.de/session/analytics-age-internet-things","analytics in the age of the internet of things"],["http://2015.berlinbuzzwords.de/session/its-all-fun-and-games-until-tale-repetitive-stress-injury","its all fun and games until a tale of repetitive stress injury"],["http://2015.berlinbuzzwords.de/session/online-learning-vowpal-wabbit-and-hadoop","online learning vowpal wabbit and hadoop"],["http://2015.berlinbuzzwords.de/session/model-code-how-automate-deployment-r-models-production-environment","model as code how to automate the deployment of r models in production environment"],["http://2015.berlinbuzzwords.de/session/teaming-heterogeneous-sports-data-building-360o-view-fifa-world-cup","teaming up heterogeneous sports data building a 360 view of the fifa world cup"],["http://2015.berlinbuzzwords.de/session/understanding-whats-important","understanding whats important"],["http://2015.berlinbuzzwords.de/session/kibana-4-towards-beer-analytics-engine","kibana 4 towards a beer analytics engine"],["http://2015.berlinbuzzwords.de/session/using-apache-spark-graph-computation-neo4j","using apache spark for graph computation with neo4j"],["http://2015.berlinbuzzwords.de/session/automating-cassandra-repairs","automating cassandra repairs"],["http://2015.berlinbuzzwords.de/session/recommendation-scale","recommendation at scale"],["http://2015.berlinbuzzwords.de/session/prediction-criteo-learning-scale-hadoop","prediction criteo learning at scale on hadoop"],["http://2015.berlinbuzzwords.de/session/new-cuda-concepts-and-apis","new cuda concepts and apis"],["http://2015.berlinbuzzwords.de/session/analyzing-and-searching-streams-social-media-scale-using-spark-kafka-and-elasticsearch","analyzing and searching streams of social media at scale using spark kafka and elasticsearch"],["http://2015.berlinbuzzwords.de/session/so-you-want-be-data-science-consultant-or-hire-one-10-things-you-should-know","so you want to be a data science consultant or hire one 10 things you should know"],["http://2015.berlinbuzzwords.de/session/what-and-why-and-how-apache-drill-10","what and why and how apache drill 10"]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"link","type":"\"string\""},{"name":"title","type":"\"string\""}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":null,"error":null,"workflows":[],"startTime":1.465307881485E12,"submitTime":1.46530788262E12,"finishTime":1.465307886177E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"Extracting Actual Session Pages","showCommandTitle":true,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"ab793d53-a0b6-4639-aa3b-bf6fe9d8b799"},{"version":"CommandV1","origId":2469000391151340,"guid":"19606a57-6768-4697-a07d-9d0cab932991","subtype":"command","commandType":"auto","position":2.98828125,"command":"display(sessions.groupBy(\"year\").count().orderBy(\"year\"))","commandVersion":0,"state":"finished","results":{"type":"table","data":[["2010",10.0],["2011",49.0],["2012",59.0],["2013",38.0],["2014",59.0],["2015",55.0],["2016",52.0]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"year","type":"\"string\""},{"name":"count","type":"\"long\""}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":null,"error":null,"workflows":[],"startTime":1.465307892534E12,"submitTime":1.465307893679E12,"finishTime":1.465307896107E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"barChart","width":"660","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"Sessions Per Year (scraped)","showCommandTitle":true,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"98679d92-bb2f-4b62-928a-93e46c6bf223"},{"version":"CommandV1","origId":2469000391151341,"guid":"229f582c-1cb0-4a0f-af49-d22fe82f7142","subtype":"command","commandType":"auto","position":2.994140625,"command":"display(sqlContext.createDataFrame(\n    sessions.select(\"speakers\")\n            .flatMap(lambda line: line.speakers)\n            .map(lambda x: (x, 1))\n            .reduceByKey(lambda a, b: a + b)\n            .map(lambda x: Row(speaker=x[0], talks=x[1]))\n).orderBy('talks', ascending=False))","commandVersion":0,"state":"finished","results":{"type":"table","data":[["ted dunning",9.0],["grant ingersoll",6.0],["eric evans",6.0],["uwe schindler",6.0],["rafa? ku?",5.0],["michael busch",4.0],["shay banon",4.0],["robert muir",4.0],["friso van vollenhoven",3.0],["steve loughran",3.0],["christoph goller",3.0],["michael hunger",3.0],["everyone",3.0],["stephan ewen",3.0],["julien nioche",3.0],["radu gheorghe",3.0],["martijn van groningen",3.0],["nick burch",3.0],["ellen friedman",3.0],["frank scholten",3.0],["mikio braun",3.0],["andrew psaltis",3.0],["simon willnauer",3.0],["sergii khomenko",2.0],["sean cribbs",2.0],["vasia kalavri",2.0],["felipe hoffa",2.0],["thomas fricke",2.0],["fabian hueske",2.0],["jakob homan",2.0],["peter bourgon",2.0],["mark miller",2.0],["andrew clegg",2.0],["till rohrmann",2.0],["david whiting",2.0],["alvaro videla",2.0],["james stanier",2.0],["jonathan gray",2.0],["dawid weiss",2.0],["gary dusbabek",2.0],["martin kleppmann",2.0],["christoph tavan",2.0],["michael hausenblas",2.0],["adrien grand",2.0],["andrzej bialecki",2.0],["alan gates",2.0],["rashid khan",2.0],["mikhail khludnev",2.0],["boaz leskes",2.0],["sylvain lebresne",2.0],["kai voigt",2.0],["otis gospodneti?",2.0],["lars george",2.0],["roman shaposhnik",2.0],["clinton gormley",2.0],["georgi knox",2.0],["tim lossen",2.0],["owen o'malley",2.0],["michal rutkowski",2.0],["heloise nonne",2.0],["christian moen",2.0],["patrick callaghan",2.0],["britta weber",2.0],["michael kaisser",2.0],["matthieu vautrot",2.0],["tudor golubenco",1.0],["michael kleen",1.0],["steffen bickel",1.0],["christoph schmitz",1.0],["enrico canzonieri",1.0],["volker janz",1.0],["markus lorch",1.0],["gerd könig",1.0],["jordan mendelson",1.0],["christopher batey",1.0],["martin scholl",1.0],["tugdual grall",1.0],["jim webber",1.0],["zeno gantner",1.0],["andré bois-crettez",1.0],["isabelle robin",1.0],["itamar syn-hershko",1.0],["nina bertrand",1.0],["ramkumar aiyengar",1.0],["nuno job",1.0],["patrick peschlow",1.0],["andrej rosenheinrich",1.0],["ranbir chawla",1.0],["ralf herbrich",1.0],["nicolas spiegelberg",1.0],["tobias kuhn",1.0],["daniel trümper",1.0],["ryan zezeski",1.0],["radu chilom",1.0],["neha narkhede",1.0],["nico kruber",1.0],["maximilian michels",1.0],["dmitry mescheryakov",1.0],["ian plosker",1.0],["jitendra pandey",1.0],["philipp fehre",1.0],["karel minarik",1.0],["daniel molnar",1.0],["stanislaw osinski",1.0],["andreas neumann",1.0],["edit kiss",1.0],["stefan pohl",1.0],["daniel einspanjer",1.0],["markus klose",1.0],["mircea markus",1.0],["markus weimer",1.0],["szehon ho",1.0],["sean owen",1.0],["jochen jörg",1.0],["siem vaessen",1.0],["peter voss",1.0],["ema iancuta",1.0],["carlos baquero",1.0],["chris ward",1.0],["toke eskildsen",1.0],["michael wallace",1.0],["nakul selvaraj",1.0],["christian richter",1.0],["anca kopetz",1.0],["stefan groschupf",1.0],["barrie kersbergen",1.0],["dan filimon",1.0],["doug cutting",1.0],["omer trajman",1.0],["michael brückner",1.0],["michael stack",1.0],["hannes kruppa",1.0],["chris hostetter",1.0],["ivan mamontov",1.0],["monica sarbu",1.0],["flavio junqueira",1.0],["dale harvey",1.0],["ralf neeb",1.0],["marcel kornacker",1.0],["alex brasetvik",1.0],["ewa gasperowicz",1.0],["niels basjes",1.0],["kris geusebroek",1.0],["fabrizio manfredi",1.0],["diane mueller-klingspor",1.0],["robert metzger",1.0],["stefan siprell",1.0],["jan graßegger",1.0],["chris harris",1.0],["chris wensel",1.0],["frank conrad",1.0],["joseph turian",1.0],["dominic heger",1.0],["jan lehnardt",1.0],["oleg zhurakousky",1.0],["julien le dem",1.0],["alexander sibiryakov",1.0],["jonathan ellis",1.0],["ioan eugen stan",1.0],["todd lipcon",1.0],["christian gügi",1.0],["simon dollé",1.0],["hendrik muhs",1.0],["marc schwering",1.0],["chris male",1.0],["javier ramirez",1.0],["olivier toromanoff",1.0],["thomas koch",1.0],["niko schmuck",1.0],["doug judd",1.0],["pavlo baron",1.0],["paolo fragomeni",1.0],["shikhar bhushan",1.0],["kashif rasul",1.0],["alan woodward",1.0],["shalin shekhar mangar",1.0],["joel westberg",1.0],["jukka zitting",1.0],["radim ?eh??ek",1.0],["galina hinova",1.0],["ryan ernst",1.0],["florian pfeiffer",1.0],["andrzej bia?ecki",1.0],["mathias stearn",1.0],["luká? vl?ek",1.0],["dragan milosevic",1.0],["breno faria",1.0],["fabian wilckens",1.0],["katherine daniels",1.0],["felix geisendörfer",1.0],["bertrand delacretaz",1.0],["shevek",1.0],["jodok batlogg",1.0],["konark modi",1.0],["rod cope",1.0],["tobias kässmann",1.0],["clément stenac",1.0],["michael noll",1.0],["steven noels",1.0],["stefan schadwinkel",1.0],["debarshi basak",1.0],["dominik benz",1.0],["stefan savev",1.0],["mathias meyer",1.0],["ludwine probst",1.0],["peter karich",1.0],["eugen funk",1.0],["matt patterson",1.0],["ira cohen",1.0],["ameya kanitkar",1.0],["alex baranau",1.0],["dirk primbs",1.0],["sam bessalah",1.0],["alex pinkin",1.0],["james goodwin",1.0],["neha narula",1.0],["will hayes",1.0],["federico mosca",1.0],["jean-daniel cryans",1.0],["alex lloyd",1.0],["nitay joffe",1.0],["ariel waldman",1.0],["aaron beppu",1.0],["dmitry stratiychuk",1.0],["devaraj das",1.0],["andré lynum",1.0],["matthias wessendorf",1.0],["wolfgang hoschek",1.0],["christoffer vig",1.0],["radovan zvoncek",1.0],["leslie hawthorn",1.0],["torsten curdt",1.0]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"speaker","type":"\"string\""},{"name":"talks","type":"\"long\""}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":null,"error":null,"workflows":[],"startTime":1.465307898936E12,"submitTime":1.46530790008E12,"finishTime":1.46530790228E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"Top Speakers","showCommandTitle":true,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"0bbc635e-c859-4b80-a149-5f63e7973f44"},{"version":"CommandV1","origId":2469000391151342,"guid":"fa063a71-965d-4d75-bf32-baeac6a2b5c4","subtype":"command","commandType":"auto","position":2.9970703125,"command":"counts = sqlContext.createDataFrame(\n    sessions.select(\"body\") \\\n            .flatMap(lambda line: line.body.split(\" \")) \\\n            .map(lambda word: (word, 1)) \\\n            .reduceByKey(lambda a, b: a + b) \\\n            .map(lambda a: Row(word=a[0], count=a[1])) \\\n)\ncounts.registerTempTable(\"wordcounts\")\ntop_counts = sqlContext.sql(\"SELECT word, count FROM wordcounts ORDER BY count DESC LIMIT 50\")\ndisplay(top_counts)","commandVersion":0,"state":"finished","results":{"type":"table","data":[["data",516.0],["talk",332.0],["system",194.0],["apache",190.0],["hadoop",166.0],["use",157.0],["search",152.0],["application",145.0],["using",139.0],["well",135.0],["new",128.0],["lucene",124.0],["processing",122.0],["elasticsearch",121.0],["realtime",114.0],["like",107.0],["solr",107.0],["project",106.0],["stream",103.0],["distributed",102.0],["also",102.0],["algorithm",101.0],["used",96.0],["user",93.0],["scale",90.0],["time",81.0],["provide",81.0],["show",81.0],["model",80.0],["performance",80.0],["many",80.0],["cluster",79.0],["feature",78.0],["opensource",78.0],["hbase",76.0],["large",76.0],["one",70.0],["work",70.0],["query",68.0],["make",68.0],["based",67.0],["mapreduce",66.0],["analytic",64.0],["database",64.0],["result",63.0],["querie",63.0],["bigdata",62.0],["solution",60.0],["tool",59.0],["building",59.0]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"word","type":"\"string\""},{"name":"count","type":"\"long\""}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":null,"error":null,"workflows":[],"startTime":1.465307902336E12,"submitTime":1.465307903495E12,"finishTime":1.465307905758E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"The Buzzwords of Berlin Buzzwords","showCommandTitle":true,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"29313371-7256-496e-af10-1c9ffe3d6dbb"},{"version":"CommandV1","origId":2469000391151343,"guid":"937ed410-7dd2-4bb3-805a-a47943cbff15","subtype":"command","commandType":"auto","position":2.99853515625,"command":"counts = sqlContext.createDataFrame(\n    sessions.select('year', 'body') \\\n            .flatMap(lambda line: [(line.year, word) for word in line.body.split(\" \")]) \\\n            .map(lambda line: ((line[0], line[1]), 1)) \\\n            .reduceByKey(lambda a, b: a + b) \\\n            .map(lambda a: Row(year=a[0][0], word=a[0][1], count=a[1])) \\\n)\ncounts.registerTempTable(\"wordcounts_per_year\")\ntop_counts = sqlContext.sql(\"SELECT year, word, count FROM wordcounts_per_year ORDER BY count DESC LIMIT 50\")\ndisplay(top_counts)","commandVersion":0,"state":"finished","results":{"type":"table","data":[["2015","data",109.0],["2012","data",105.0],["2012","talk",104.0],["2016","data",103.0],["2014","data",73.0],["2013","data",73.0],["2012","hadoop",61.0],["2014","talk",56.0],["2016","stream",55.0],["2016","apache",51.0],["2012","watch",49.0],["2011","data",49.0],["2012","video",47.0],["2015","talk",46.0],["2016","system",44.0],["2016","talk",42.0],["2013","talk",41.0],["2014","system",40.0],["2014","use",39.0],["2012","lucene",39.0],["2011","talk",36.0],["2015","apache",35.0],["2012","hbase",35.0],["2015","system",35.0],["2014","apache",34.0],["2011","search",32.0],["2016","processing",32.0],["2014","elasticsearch",30.0],["2013","elasticsearch",30.0],["2012","mapreduce",30.0],["2011","hadoop",30.0],["2016","new",30.0],["2012","processing",30.0],["2014","application",29.0],["2012","use",29.0],["2014","search",29.0],["2015","spark",28.0],["2016","kafka",28.0],["2012","well",28.0],["2015","well",28.0],["2013","well",27.0],["2016","distributed",27.0],["2012","system",27.0],["2012","model",27.0],["2016","streaming",27.0],["2012","one",27.0],["2013","algorithm",27.0],["2013","use",27.0],["2014","hadoop",27.0],["2016","application",27.0]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"year","type":"\"string\""},{"name":"word","type":"\"string\""},{"name":"count","type":"\"long\""}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":null,"error":null,"workflows":[],"startTime":1.465307905766E12,"submitTime":1.465307906171E12,"finishTime":1.46530790923E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"Buzzwords Per Year","showCommandTitle":true,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"fac96a1d-7733-4499-8c51-c5c7e5661fc3"},{"version":"CommandV1","origId":2469000391151345,"guid":"0db5e386-7427-445f-92d3-8debce7fed26","subtype":"command","commandType":"auto","position":2.999267578125,"command":"def timeline(terms):\n    return sqlContext.sql(\"\"\"\nSELECT year, word, count FROM wordcounts_per_year\nWHERE word IN ('%s')\nORDER BY year, count ASC\n\"\"\" % (\"', '\".join(terms)))\n\ndef timelineRelative(terms):\n    return sqlContext.sql(\"\"\"\nSELECT w.year, word, count, count / total * 100 as relative_count FROM wordcounts_per_year w LEFT JOIN (SELECT year, sum(count) as total FROM wordcounts_per_year GROUP BY year) t ON (w.year = t.year)\nWHERE word IN ('%s')\nORDER BY year, count ASC\n\"\"\" % (\"', '\".join(terms))) ","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1.465307909241E12,"submitTime":1.46530790715E12,"finishTime":1.465307909314E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"Plot Timelines","showCommandTitle":true,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"56f14b35-18b9-4bb7-8990-323d06d753cd"},{"version":"CommandV1","origId":2469000391151348,"guid":"192939e1-0b8b-4310-8e2b-da569382d642","subtype":"command","commandType":"auto","position":2.999359130859375,"command":"display(timeline([\n  'lucene',\n  'solr',\n  'elasticsearch',\n]))   ","commandVersion":0,"state":"finished","results":{"type":"table","data":[["2010","elasticsearch",3.0],["2010","solr",5.0],["2010","lucene",11.0],["2011","elasticsearch",7.0],["2011","lucene",14.0],["2011","solr",18.0],["2012","solr",17.0],["2012","elasticsearch",21.0],["2012","lucene",39.0],["2013","solr",15.0],["2013","lucene",15.0],["2013","elasticsearch",30.0],["2014","lucene",16.0],["2014","solr",21.0],["2014","elasticsearch",30.0],["2015","solr",16.0],["2015","lucene",21.0],["2015","elasticsearch",26.0],["2016","elasticsearch",4.0],["2016","lucene",8.0],["2016","solr",15.0]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"year","type":"\"string\""},{"name":"word","type":"\"string\""},{"name":"count","type":"\"long\""}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":null,"error":null,"workflows":[],"startTime":1.465307909326E12,"submitTime":1.46530790789E12,"finishTime":1.46530790953E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"lineChart","width":"660","height":"auto","xColumns":["year"],"yColumns":["count"],"pivotColumns":["word"],"pivotAggregation":"sum","customPlotOptions":{"barChart":[{"key":"grouped","value":true},{"key":"stacked","value":false},{"key":"100_stacked","value":false}],"lineChart":[]},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"2dd67dce-ac00-46f0-ada5-d42c0512e6a6"},{"version":"CommandV1","origId":2469000391151347,"guid":"afb0a4ca-c4cd-4624-a7ac-ab5a36de6e78","subtype":"command","commandType":"auto","position":2.99945068359375,"command":"display(timelineRelative([\n  'lucene',\n  'solr',\n  'elasticsearch',\n]))   ","commandVersion":0,"state":"finished","results":{"type":"table","data":[["2010","elasticsearch",3.0,0.49261083743842365],["2010","solr",5.0,0.8210180623973727],["2010","lucene",11.0,1.8062397372742198],["2011","elasticsearch",7.0,0.22264631043256997],["2011","lucene",14.0,0.44529262086513993],["2011","solr",18.0,0.5725190839694656],["2012","solr",17.0,0.33696729435084244],["2012","elasticsearch",21.0,0.41625371655104065],["2012","lucene",39.0,0.7730426164519326],["2013","lucene",15.0,0.40214477211796246],["2013","solr",15.0,0.40214477211796246],["2013","elasticsearch",30.0,0.8042895442359249],["2014","lucene",16.0,0.38022813688212925],["2014","solr",21.0,0.4990494296577947],["2014","elasticsearch",30.0,0.7129277566539924],["2015","solr",16.0,0.3553976010661928],["2015","lucene",21.0,0.46645935139937805],["2015","elasticsearch",26.0,0.5775211017325633],["2016","elasticsearch",4.0,0.08110300081103002],["2016","lucene",8.0,0.16220600162206003],["2016","solr",15.0,0.30413625304136255]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"year","type":"\"string\""},{"name":"word","type":"\"string\""},{"name":"count","type":"\"long\""},{"name":"relative_count","type":"\"double\""}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":null,"error":null,"workflows":[],"startTime":1.465307909542E12,"submitTime":1.465307908897E12,"finishTime":1.4653079109E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"lineChart","width":"660","height":"auto","xColumns":["year"],"yColumns":["relative_count"],"pivotColumns":["word"],"pivotAggregation":"sum","customPlotOptions":{"barChart":[{"key":"grouped","value":true},{"key":"stacked","value":false},{"key":"100_stacked","value":false}],"lineChart":[]},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"233a4928-4064-45e9-9e5a-5f36f1a0ca23"},{"version":"CommandV1","origId":2469000391151350,"guid":"12800c8c-de27-4327-b5ae-bf3284d9fa3a","subtype":"command","commandType":"auto","position":2.999453544616699,"command":"display(timelineRelative([\n  'storm',\n  'flink',\n  'spark',\n]))","commandVersion":0,"state":"finished","results":{"type":"table","data":[["2011","storm",3.0,0.09541984732824427],["2012","storm",4.0,0.07928642220019821],["2013","storm",2.0,0.05361930294906167],["2014","storm",2.0,0.04752851711026616],["2014","spark",6.0,0.14258555133079848],["2015","storm",8.0,0.1776988005330964],["2015","flink",12.0,0.26654820079964464],["2015","spark",28.0,0.6219458018658374],["2016","storm",9.0,0.18248175182481752],["2016","spark",22.0,0.4460665044606651],["2016","flink",26.0,0.527169505271695]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"year","type":"\"string\""},{"name":"word","type":"\"string\""},{"name":"count","type":"\"long\""},{"name":"relative_count","type":"\"double\""}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":null,"error":null,"workflows":[],"startTime":1.46530791091E12,"submitTime":1.465307909727E12,"finishTime":1.465307911966E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"lineChart","width":"660","height":"auto","xColumns":["year"],"yColumns":["relative_count"],"pivotColumns":["word"],"pivotAggregation":"sum","customPlotOptions":{"barChart":[{"key":"grouped","value":true},{"key":"stacked","value":false},{"key":"100_stacked","value":false}],"lineChart":[]},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"fcdc0028-ce5f-4a48-9dbd-730be2c2e412"},{"version":"CommandV1","origId":2469000391151353,"guid":"9f6b9818-d3a9-4114-866a-3edf63711d9e","subtype":"command","commandType":"auto","position":2.9994735717773438,"command":"display(timelineRelative([\n  'hadoop',\n  'mapreduce',\n  'hdf',\n  'yarn',\n  'nosql',\n  'sql',\n]))  ","commandVersion":0,"state":"finished","results":{"type":"table","data":[["2010","nosql",1.0,0.16420361247947454],["2010","mapreduce",2.0,0.3284072249589491],["2010","hadoop",6.0,0.9852216748768473],["2011","hdf",1.0,0.031806615776081425],["2011","sql",4.0,0.1272264631043257],["2011","mapreduce",11.0,0.34987277353689566],["2011","nosql",16.0,0.5089058524173028],["2011","hadoop",30.0,0.9541984732824428],["2012","nosql",6.0,0.11892963330029734],["2012","hdf",8.0,0.15857284440039643],["2012","mapreduce",30.0,0.5946481665014867],["2012","hadoop",61.0,1.2091179385530229],["2013","nosql",1.0,0.026809651474530835],["2013","hdf",2.0,0.05361930294906167],["2013","mapreduce",4.0,0.10723860589812334],["2013","sql",8.0,0.21447721179624668],["2013","hadoop",24.0,0.6434316353887399],["2014","sql",3.0,0.07129277566539924],["2014","hdf",3.0,0.07129277566539924],["2014","mapreduce",8.0,0.19011406844106463],["2014","yarn",17.0,0.40399239543726234],["2014","hadoop",27.0,0.6416349809885932],["2015","yarn",1.0,0.02221235006663705],["2015","hdf",2.0,0.0444247001332741],["2015","mapreduce",3.0,0.06663705019991116],["2015","sql",7.0,0.15548645046645934],["2015","hadoop",8.0,0.1776988005330964],["2016","hdf",2.0,0.04055150040551501],["2016","sql",6.0,0.12165450121654502],["2016","nosql",7.0,0.14193025141930252],["2016","mapreduce",8.0,0.16220600162206003],["2016","hadoop",10.0,0.202757502027575]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"year","type":"\"string\""},{"name":"word","type":"\"string\""},{"name":"count","type":"\"long\""},{"name":"relative_count","type":"\"double\""}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":null,"error":null,"workflows":[],"startTime":1.465307911975E12,"submitTime":1.465307910577E12,"finishTime":1.46530791295E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"lineChart","width":"660","height":"auto","xColumns":["year"],"yColumns":["relative_count"],"pivotColumns":["word"],"pivotAggregation":"sum","customPlotOptions":{"barChart":[{"key":"grouped","value":true},{"key":"stacked","value":false},{"key":"100_stacked","value":false}],"lineChart":[]},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"38873658-063d-4627-a9c5-5646786ae089"},{"version":"CommandV1","origId":2469000391151354,"guid":"8cf16538-b690-4cc9-8ea4-48466601758b","subtype":"command","commandType":"auto","position":2.9994964599609375,"command":"display(timelineRelative([\n  'nosql',\n  'sql',\n  'graph',\n]))   ","commandVersion":0,"state":"finished","results":{"type":"table","data":[["2010","nosql",1.0,0.16420361247947454],["2011","graph",4.0,0.1272264631043257],["2011","sql",4.0,0.1272264631043257],["2011","nosql",16.0,0.5089058524173028],["2012","nosql",6.0,0.11892963330029734],["2012","graph",15.0,0.29732408325074333],["2013","nosql",1.0,0.026809651474530835],["2013","sql",8.0,0.21447721179624668],["2013","graph",8.0,0.21447721179624668],["2014","sql",3.0,0.07129277566539924],["2014","graph",15.0,0.3564638783269962],["2015","graph",3.0,0.06663705019991116],["2015","sql",7.0,0.15548645046645934],["2016","sql",6.0,0.12165450121654502],["2016","nosql",7.0,0.14193025141930252],["2016","graph",10.0,0.202757502027575]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"year","type":"\"string\""},{"name":"word","type":"\"string\""},{"name":"count","type":"\"long\""},{"name":"relative_count","type":"\"double\""}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":null,"error":null,"workflows":[],"startTime":1.465307912958E12,"submitTime":1.465307911173E12,"finishTime":1.465307913828E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"lineChart","width":"660","height":"auto","xColumns":["year"],"yColumns":["relative_count"],"pivotColumns":["word"],"pivotAggregation":"sum","customPlotOptions":{"barChart":[{"key":"grouped","value":true},{"key":"stacked","value":false},{"key":"100_stacked","value":false}],"lineChart":[]},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"f654cdfd-1f7d-411b-b495-5b5d685137f6"},{"version":"CommandV1","origId":2469000391151355,"guid":"00342832-9b4d-4b56-93d1-557023e729ce","subtype":"command","commandType":"auto","position":2.9995079040527344,"command":"display(timelineRelative([\n  'cassandra',\n  'hbase',\n  'redi',\n  'riak',\n  'couchdb',\n  'mongodb',\n]))   ","commandVersion":0,"state":"finished","results":{"type":"table","data":[["2010","hbase",1.0,0.16420361247947454],["2011","riak",2.0,0.06361323155216285],["2011","mongodb",3.0,0.09541984732824427],["2011","redi",4.0,0.1272264631043257],["2011","couchdb",6.0,0.19083969465648853],["2011","cassandra",7.0,0.22264631043256997],["2011","hbase",16.0,0.5089058524173028],["2012","riak",3.0,0.05946481665014867],["2012","cassandra",4.0,0.07928642220019821],["2012","mongodb",4.0,0.07928642220019821],["2012","hbase",35.0,0.6937561942517344],["2013","mongodb",1.0,0.026809651474530835],["2013","riak",4.0,0.10723860589812334],["2013","hbase",4.0,0.10723860589812334],["2013","couchdb",9.0,0.2412868632707775],["2013","cassandra",10.0,0.2680965147453083],["2014","mongodb",1.0,0.02376425855513308],["2014","riak",2.0,0.04752851711026616],["2014","redi",6.0,0.14258555133079848],["2014","cassandra",12.0,0.28517110266159695],["2014","hbase",13.0,0.30893536121673004],["2015","redi",1.0,0.02221235006663705],["2015","hbase",3.0,0.06663705019991116],["2015","cassandra",12.0,0.26654820079964464],["2016","redi",1.0,0.020275750202757504],["2016","hbase",4.0,0.08110300081103002],["2016","cassandra",6.0,0.12165450121654502]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"year","type":"\"string\""},{"name":"word","type":"\"string\""},{"name":"count","type":"\"long\""},{"name":"relative_count","type":"\"double\""}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":null,"error":null,"workflows":[],"startTime":1.46530791384E12,"submitTime":1.465307911758E12,"finishTime":1.465307914785E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"lineChart","width":"660","height":"auto","xColumns":["year"],"yColumns":["relative_count"],"pivotColumns":["word"],"pivotAggregation":"sum","customPlotOptions":{"barChart":[{"key":"grouped","value":true},{"key":"stacked","value":false},{"key":"100_stacked","value":false}],"lineChart":[]},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"f9236b51-9801-42d0-aded-8008de7fbc33"},{"version":"CommandV1","origId":2469000391151356,"guid":"98c57289-b713-4644-8412-d83336f000a7","subtype":"command","commandType":"auto","position":2.999513626098633,"command":"display(timelineRelative([\n  'streaming',\n  'realtime',\n  'batch',\n]))   ","commandVersion":0,"state":"finished","results":{"type":"table","data":[["2010","realtime",3.0,0.49261083743842365],["2011","batch",1.0,0.031806615776081425],["2011","realtime",10.0,0.3180661577608142],["2012","batch",6.0,0.11892963330029734],["2012","realtime",25.0,0.4955401387512388],["2013","streaming",2.0,0.05361930294906167],["2013","batch",3.0,0.08042895442359249],["2013","realtime",20.0,0.5361930294906166],["2014","batch",7.0,0.16634980988593154],["2014","streaming",9.0,0.21387832699619772],["2014","realtime",16.0,0.38022813688212925],["2015","batch",6.0,0.13327410039982232],["2015","streaming",7.0,0.15548645046645934],["2015","realtime",18.0,0.3998223011994669],["2016","batch",9.0,0.18248175182481752],["2016","realtime",22.0,0.4460665044606651],["2016","streaming",27.0,0.5474452554744526]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"year","type":"\"string\""},{"name":"word","type":"\"string\""},{"name":"count","type":"\"long\""},{"name":"relative_count","type":"\"double\""}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":null,"error":null,"workflows":[],"startTime":1.465307914793E12,"submitTime":1.465307912239E12,"finishTime":1.465307915663E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"lineChart","width":"660","height":"auto","xColumns":["year"],"yColumns":["relative_count"],"pivotColumns":["word"],"pivotAggregation":"sum","customPlotOptions":{"barChart":[{"key":"grouped","value":true},{"key":"stacked","value":false},{"key":"100_stacked","value":false}],"lineChart":[]},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"479d9749-f0a6-418b-a785-afc8663225cb"},{"version":"CommandV1","origId":2469000391151357,"guid":"cfc7d713-706d-4673-b37c-e7190fbf2d81","subtype":"command","commandType":"auto","position":2.999516487121582,"command":"display(timelineRelative([\n  'hive',\n  'pig',\n  'impala',\n  'presto',\n  'sparksql',\n  'drill',\n]))   ","commandVersion":0,"state":"finished","results":{"type":"table","data":[["2011","pig",1.0,0.031806615776081425],["2011","hive",2.0,0.06361323155216285],["2012","pig",5.0,0.09910802775024777],["2012","hive",10.0,0.19821605550049554],["2013","pig",4.0,0.10723860589812334],["2013","impala",8.0,0.21447721179624668],["2013","drill",11.0,0.2949061662198391],["2013","hive",19.0,0.5093833780160858],["2014","pig",1.0,0.02376425855513308],["2014","drill",1.0,0.02376425855513308],["2014","impala",1.0,0.02376425855513308],["2014","hive",6.0,0.14258555133079848],["2015","impala",1.0,0.02221235006663705],["2015","sparksql",1.0,0.02221235006663705],["2015","hive",7.0,0.15548645046645934],["2015","drill",15.0,0.33318525099955576],["2016","impala",1.0,0.020275750202757504],["2016","drill",2.0,0.04055150040551501]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"year","type":"\"string\""},{"name":"word","type":"\"string\""},{"name":"count","type":"\"long\""},{"name":"relative_count","type":"\"double\""}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":null,"error":null,"workflows":[],"startTime":1.465307915673E12,"submitTime":1.465307912814E12,"finishTime":1.465307916426E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"lineChart","width":"660","height":"auto","xColumns":["year"],"yColumns":["relative_count"],"pivotColumns":["word"],"pivotAggregation":"sum","customPlotOptions":{"barChart":[{"key":"grouped","value":true},{"key":"stacked","value":false},{"key":"100_stacked","value":false}],"lineChart":[]},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"704696a2-e533-4250-b5c4-332d8c6a8b02"},{"version":"CommandV1","origId":2469000391151358,"guid":"daef163a-9035-49dd-bdc3-2686f033302f","subtype":"command","commandType":"auto","position":2.9995293617248535,"command":"display(timelineRelative([\n  'crunch',\n  'eventsourcing',\n  'blockchain',\n]))   ","commandVersion":0,"state":"finished","results":{"type":"table","data":[["2014","crunch",2.0,0.04752851711026616],["2016","eventsourcing",2.0,0.04055150040551501],["2016","crunch",3.0,0.06082725060827251],["2016","blockchain",4.0,0.08110300081103002]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"year","type":"\"string\""},{"name":"word","type":"\"string\""},{"name":"count","type":"\"long\""},{"name":"relative_count","type":"\"double\""}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":null,"error":null,"workflows":[],"startTime":1.465307916435E12,"submitTime":1.465307913291E12,"finishTime":1.465307917309E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"lineChart","width":"660","height":"auto","xColumns":["year"],"yColumns":["relative_count"],"pivotColumns":["word"],"pivotAggregation":"sum","customPlotOptions":{"barChart":[{"key":"grouped","value":true},{"key":"stacked","value":false},{"key":"100_stacked","value":false}],"lineChart":[]},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"1e09fd89-8349-4bea-bd46-eead162b518a"},{"version":"CommandV1","origId":2469000391151349,"guid":"a1b53547-cce1-4516-84ba-b51748c7cae2","subtype":"command","commandType":"auto","position":2.999542236328125,"command":"old = ['hadoop', 'mapreduce', 'hdf']\nnew = ['spark', 'flink', 'storm']\n\ndisplay(sqlContext.sql(\"\"\"\nSELECT w.year, CASE WHEN word in ('%s') THEN 'hadoop+mapreduce+hdfs' ELSE 'spark+flink+storm' END AS technology, count, count / total * 100 as relative_count\nFROM wordcounts_per_year w LEFT JOIN (SELECT year, sum(count) as total FROM wordcounts_per_year GROUP BY year) t ON (w.year = t.year)\nWHERE word IN ('%s')\nORDER BY year, count ASC\n\"\"\" % (\"', '\".join(old), \"', '\".join(old + new))))","commandVersion":0,"state":"finished","results":{"type":"table","data":[["2010","hadoop+mapreduce+hdfs",2.0,0.3284072249589491],["2010","hadoop+mapreduce+hdfs",6.0,0.9852216748768473],["2011","hadoop+mapreduce+hdfs",1.0,0.031806615776081425],["2011","spark+flink+storm",3.0,0.09541984732824427],["2011","hadoop+mapreduce+hdfs",11.0,0.34987277353689566],["2011","hadoop+mapreduce+hdfs",30.0,0.9541984732824428],["2012","spark+flink+storm",4.0,0.07928642220019821],["2012","hadoop+mapreduce+hdfs",8.0,0.15857284440039643],["2012","hadoop+mapreduce+hdfs",30.0,0.5946481665014867],["2012","hadoop+mapreduce+hdfs",61.0,1.2091179385530229],["2013","spark+flink+storm",2.0,0.05361930294906167],["2013","hadoop+mapreduce+hdfs",2.0,0.05361930294906167],["2013","hadoop+mapreduce+hdfs",4.0,0.10723860589812334],["2013","hadoop+mapreduce+hdfs",24.0,0.6434316353887399],["2014","spark+flink+storm",2.0,0.04752851711026616],["2014","hadoop+mapreduce+hdfs",3.0,0.07129277566539924],["2014","spark+flink+storm",6.0,0.14258555133079848],["2014","hadoop+mapreduce+hdfs",8.0,0.19011406844106463],["2014","hadoop+mapreduce+hdfs",27.0,0.6416349809885932],["2015","hadoop+mapreduce+hdfs",2.0,0.0444247001332741],["2015","hadoop+mapreduce+hdfs",3.0,0.06663705019991116],["2015","spark+flink+storm",8.0,0.1776988005330964],["2015","hadoop+mapreduce+hdfs",8.0,0.1776988005330964],["2015","spark+flink+storm",12.0,0.26654820079964464],["2015","spark+flink+storm",28.0,0.6219458018658374],["2016","hadoop+mapreduce+hdfs",2.0,0.04055150040551501],["2016","hadoop+mapreduce+hdfs",8.0,0.16220600162206003],["2016","spark+flink+storm",9.0,0.18248175182481752],["2016","hadoop+mapreduce+hdfs",10.0,0.202757502027575],["2016","spark+flink+storm",22.0,0.4460665044606651],["2016","spark+flink+storm",26.0,0.527169505271695]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"year","type":"\"string\""},{"name":"technology","type":"\"string\""},{"name":"count","type":"\"long\""},{"name":"relative_count","type":"\"double\""}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null},"errorSummary":null,"error":null,"workflows":[],"startTime":1.465307917318E12,"submitTime":1.465307913691E12,"finishTime":1.465307918183E12,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"lineChart","width":"660","height":"auto","xColumns":["year"],"yColumns":["relative_count"],"pivotColumns":["technology"],"pivotAggregation":"sum","customPlotOptions":{"barChart":[{"key":"grouped","value":true},{"key":"stacked","value":false},{"key":"100_stacked","value":false}],"lineChart":[]},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"\"Old\" vs \"New\"","showCommandTitle":true,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"d63859c2-b4ce-44ed-ba10-fea4c20f9689"},{"version":"CommandV1","origId":2469000391151346,"guid":"8d5c4f27-5507-4e0a-ab28-548c90d0423b","subtype":"command","commandType":"auto","position":2.9996337890625,"command":"","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"MORE BACKUP STUFF BELOW","showCommandTitle":true,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"dd7ba2a4-cce9-43d5-947b-ebf1ac331cf6"},{"version":"CommandV1","origId":183210672370559,"guid":"765e8e7b-b96d-403c-ab7f-d5e663c5a753","subtype":"command","commandType":"auto","position":3.0,"command":"def stripArray(x):\n    return [element.lower().strip() for element in x]\nsqlContext.registerFunction(\"stripArray\", stripArray, ArrayType(StringType()))","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.465238760812E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"dad6445d-3e1d-4545-aa2d-b9146b4d0a0d"},{"version":"CommandV1","origId":3074177156933413,"guid":"bf13a455-6f8d-4a8f-85fb-cdd0f485beca","subtype":"command","commandType":"auto","position":3.015625,"command":"display(sqlContext.sql(\"SELECT title, body FROM bbuzz_websites WHERE year = 2016 and (link LIKE '%/content%' OR link LIKE '%/session%') LIMIT 50\"))","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.465236518967E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"6a311bb7-d59b-410b-90f6-58390c2e0f00"},{"version":"CommandV1","origId":3729307597104037,"guid":"c06f3696-dd16-461d-af5a-0da62adff17e","subtype":"command","commandType":"auto","position":3.03125,"command":"display(sqlContext.sql(\"SELECT year, count(distinct link) as urls, sum(length(body)) as text_length, sum(length(body)) / count(distinct link) avg_document_size FROM bbuzz_websites GROUP BY year ORDER BY year\"))","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.465235966864E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"barChart","width":"660","height":"auto","xColumns":["year"],"yColumns":["avg_document_size","urls"],"pivotColumns":[],"pivotAggregation":"sum","customPlotOptions":{"barChart":[{"key":"grouped","value":true},{"key":"stacked","value":false},{"key":"100_stacked","value":false}],"lineChart":[],"areaChart":[{"key":"grouped","value":true},{"key":"stacked","value":false},{"key":"100_stacked","value":false}],"scatterPlot":[{"key":"loess","value":false},{"key":"bandwidth","value":0.3}]},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"d374db56-0d73-4208-9514-1c6373c8f4b2"},{"version":"CommandV1","origId":183210672370558,"guid":"85c1ac72-b285-478c-aad2-b5b0d0ebf974","subtype":"command","commandType":"auto","position":3.212890625,"command":"display(dbutils.fs.ls('/databricks-datasets/cs100/lab3/data-001/'))","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.465236320715E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"2b854d63-3f59-466a-b316-023b06f52f2a"},{"version":"CommandV1","origId":2219829048372530,"guid":"abdb7f15-ae44-472e-9bd4-4e1a0bbffd82","subtype":"command","commandType":"auto","position":3.2734375,"command":"display(sqlContext.sql(\"SELECT year, link, body FROM bbuzz_websites WHERE year = 2010 LIMIT 100\"))","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.465238879687E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"2595b6c6-4a42-437a-933c-92a4d2d7cf6c"},{"version":"CommandV1","origId":2219829048372531,"guid":"09633afa-2047-4624-bf71-595d34ef8f18","subtype":"command","commandType":"auto","position":3.39453125,"command":"display(sqlContext.sql(\"SELECT year, count(distinct link) as urls, sum(length(body)) as text_length, sum(length(body)) / count(distinct link) avg_document_size FROM bbuzz_websites WHERE (link LIKE '%/content%' OR link LIKE '%/session%') GROUP BY year ORDER BY year\"))","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.465235985656E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"barChart","width":"660","height":"auto","xColumns":["year"],"yColumns":["avg_document_size","urls"],"pivotColumns":[],"pivotAggregation":"sum","customPlotOptions":{"barChart":[{"key":"grouped","value":true},{"key":"stacked","value":false},{"key":"100_stacked","value":false}]},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"1766715f-7a68-466c-aab9-3117ac1bc68b"},{"version":"CommandV1","origId":3074177156933424,"guid":"8ffa5b02-9000-4750-bb61-5575f4f88122","subtype":"command","commandType":"auto","position":3.598876953125,"command":"display(sqlContext.sql(\"SELECT year, link, speakers, title FROM sessions WHERE year = 2012 ORDER BY title\"))","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.465236000583E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"e71ae169-0489-464a-9a22-049b6ea4a8b1"},{"version":"CommandV1","origId":3729307597104043,"guid":"ad02aa5c-df57-448f-a57e-a24195e32091","subtype":"command","commandType":"auto","position":3.7578125,"command":"sqlContext.registerFunction(\"array_size\", lambda x: len(x))\ndisplay(sqlContext.sql(\"SELECT year, sum(array_size(split(body, ' '))) as number_of_words FROM sessions GROUP BY year ORDER BY year\"))","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.465226987831E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"barChart","width":"660","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"1a9e25d6-e5dc-4b06-8634-5b61d7cc3c36"},{"version":"CommandV1","origId":3729307597104044,"guid":"68ac5f24-c0d8-4b64-b7cb-0c2950653a9c","subtype":"command","commandType":"auto","position":4.5,"command":"wordcounts = sqlContext.createDataFrame(sessions.select(\"body\") \\\n        .flatMap(lambda line: line.body.split(\" \")) \\\n        .map(lambda word: (word, 1)) \\\n        .reduceByKey(lambda a, b: a + b) \\\n        .map(lambda a: Row(word=a[0], count=a[1]))) \\\n        .sort(\"count\", ascending=False)\n\n\n#wordcounts.select(\"word\").rdd.map(lambda x: x[0]).collect()\n\n#http://stackoverflow.com/questions/34423281/spark-dataframe-word-count-per-document-single-row-per-document\n\n#display(sqlContext.createDataFrame(sessions.select(\"year\").distinct().map(wordcount)))","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.465226988317E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"d2a38953-eb70-4848-851c-1d7e669651f7"},{"version":"CommandV1","origId":183210672370551,"guid":"96f7e67f-d652-4c85-b4b1-567750eb4f7b","subtype":"command","commandType":"auto","position":5.0,"command":"counts = sqlContext.createDataFrame(\n    sessions.select(\"body\") \\\n            .flatMap(lambda line: line.body.split(\" \")) \\\n            .map(lambda word: (word, 1)) \\\n            .reduceByKey(lambda a, b: a + b) \\\n            .map(lambda a: Row(word=a[0], count=a[1])) \\\n)\ncounts.registerTempTable(\"wordcounts\")\ntop_counts = sqlContext.sql(\"SELECT word, count FROM wordcounts ORDER BY count DESC LIMIT 50\")\ndisplay(top_counts)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.465226989071E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"7042fedb-10c2-49a1-909f-bc6017bf9091"},{"version":"CommandV1","origId":183210672370552,"guid":"85076eb2-b2ac-4231-8962-16fe7beed4b0","subtype":"command","commandType":"auto","position":6.0,"command":"top_counts = sqlContext.sql(\"SELECT word, count FROM wordcounts ORDER BY count DESC LIMIT 50\")\ndisplay(top_counts)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.465226990313E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":["word"],"yColumns":["count"],"pivotColumns":[],"pivotAggregation":"sum","customPlotOptions":{"pieChart":[{"key":"donut","value":true}],"barChart":[{"key":"grouped","value":true},{"key":"stacked","value":false},{"key":"100_stacked","value":false}],"histogram":[{"key":"bins","value":"20"}],"areaChart":[{"key":"grouped","value":true},{"key":"stacked","value":false},{"key":"100_stacked","value":false}],"boxPlot":[],"lineChart":[]},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"d67d41df-4c37-4b72-9a03-9c8acd19bd47"},{"version":"CommandV1","origId":218688016838803,"guid":"fed888a6-ec1c-49ad-8197-e235229fa4d9","subtype":"command","commandType":"auto","position":6.375,"command":"counts = sqlContext.createDataFrame(\n    sessions.select(\"speakers\") \\\n            .flatMap(lambda line: line.speakers) \\\n            .map(lambda word: (word, 1)) \\\n            .reduceByKey(lambda a, b: a + b) \\\n            .map(lambda a: Row(word=a[0], count=a[1])) \\\n)\ncounts.registerTempTable(\"top_speakers\")\ntop_speakers = sqlContext.sql(\"SELECT word, count FROM top_speakers ORDER BY count DESC LIMIT 50\")\ndisplay(top_speakers)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.465226990949E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"Top Speakers","showCommandTitle":true,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"28fad204-c236-4150-ae4c-dc8399ca79d5"},{"version":"CommandV1","origId":2469000391151329,"guid":"4d8bc7cd-63b9-4d78-a38e-1e664537669a","subtype":"command","commandType":"auto","position":6.5625,"command":"from pyspark.ml.feature import HashingTF, IDF, Tokenizer\nfrom pyspark.mllib.feature import HashingTF as MllibHashingTF, IDF as MllibIDF\nfrom pyspark.mllib.linalg import SparseVector","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"49e9da64-6987-4df8-8ed5-6c4f3fbd65b7"},{"version":"CommandV1","origId":2219829048372534,"guid":"5f48cfad-d954-4b58-b91d-5d19a5729b66","subtype":"command","commandType":"auto","position":6.75,"command":"def run_tf_idf_spark_mllib(df, numFeatures=1 << 20):\n    tokenizer = Tokenizer(inputCol=\"body\", outputCol=\"words\")\n    wordsData = tokenizer.transform(df)\n\n    words = wordsData.select(\"words\").rdd.map(lambda x: x.words)\n\n    hashingTF = MllibHashingTF(numFeatures)\n    tf = hashingTF.transform(words)\n    tf.cache()\n\n    idf = MllibIDF().fit(tf)\n    tfidf = idf.transform(tf)\n\n    # @TODO make this nicer\n    tmp = sqlContext.createDataFrame(wordsData.rdd.zip(tfidf), [\"data\", \"features\"])\n    tmp.registerTempTable(\"tmp\")\n    old_columns = ', '.join(map(lambda x: 'data.%s' % x, wordsData.columns))\n    with_features = sqlContext.sql(\"SELECT %s, features FROM tmp\" % old_columns)\n    tmp = sqlContext.createDataFrame(with_features.rdd.zip(tf), [\"data\", \"rawFeatures\"])\n    tmp.registerTempTable(\"tmp\")\n    old_columns = ', '.join(map(lambda x: 'data.%s' % x, with_features.columns))\n    return sqlContext.sql(\"SELECT %s, rawFeatures FROM tmp\" % old_columns)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.465216190517E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"2485c89c-36ef-48a2-b8d5-a1e9a79cba17"},{"version":"CommandV1","origId":183210672370553,"guid":"c8f3cbfc-ddfb-43a8-80e4-bac65157ff87","subtype":"command","commandType":"auto","position":6.875,"command":"def run_tf_idf_spark_ml(df, numFeatures=1 << 20):\n    tokenizer = Tokenizer(inputCol=\"body\", outputCol=\"words\")\n    wordsData = tokenizer.transform(df)\n\n    hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=numFeatures)\n    featurizedData = hashingTF.transform(wordsData)\n\n    idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n    idfModel = idf.fit(featurizedData)\n\n    return idfModel.transform(featurizedData)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.465216190858E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"7342f1ed-6297-4157-8811-eb85d66e6fa7"},{"version":"CommandV1","origId":183210672370555,"guid":"308811b9-6e0a-4bdc-9f3a-766378e7a823","subtype":"command","commandType":"auto","position":6.9375,"command":"def idf_scores_for_terms(tfidf, group_key):\n\n    group_keys = tfidf.select(group_key).collect()\n    words = tfidf.select(\"words\").collect()\n    features = tfidf.select(\"features\").collect()\n    rawFeatures = tfidf.select(\"rawFeatures\").collect()\n    \n    numFeatures = features[0].features.size\n    mllibHashingTf = MllibHashingTF(numFeatures=numFeatures)\n    \n    idfscores = list()\n    for line_idx, feature_row in enumerate(features):\n        terms = dict()\n\n        for term_array in words[line_idx]:\n            for term in term_array:\n                term_index = mllibHashingTf.indexOf(term)\n                terms[term] = (feature_row.features[term_index], rawFeatures[line_idx].rawFeatures[term_index])\n        for term, score in terms.iteritems():\n            idfscores.append((group_keys[line_idx][group_key], term, float(score[0]), float(score[1])))\n\n    return idfscores","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.465216191529E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"7352fd79-0775-4a17-b767-401f2d755a95"},{"version":"CommandV1","origId":2219829048372535,"guid":"ce9355cb-62c8-4500-b0f1-6f4c4892a03c","subtype":"command","commandType":"auto","position":6.96875,"command":"tfidf = run_tf_idf_spark_mllib(sessions)\nscores = sqlContext.createDataFrame(sc.parallelize(idf_scores_for_terms(tfidf, \"link\")), [\"link\", \"term\", \"score\", \"tf\"])\nscores.registerTempTable(\"scores\")","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.465216191899E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"9148b8c0-9a0d-4fb6-a60a-025a026e4df3"},{"version":"CommandV1","origId":2219829048372538,"guid":"39b39832-c7e8-48a4-a175-bda9f7ab7451","subtype":"command","commandType":"auto","position":6.984375,"command":"top_terms = sqlContext.sql(\"SELECT term, score, tf, link FROM scores WHERE link = 'https://www.berlinbuzzwords.de/session/live-hack-analyzing-7-years-buzzwords-scale' ORDER BY score DESC\")\ndisplay(top_terms)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.46521619255E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"cd2a80cb-1479-4b6a-b500-65f8f9ddcb98"},{"version":"CommandV1","origId":2219829048372536,"guid":"6473a042-9ef3-434c-9cbf-8a28173b9ee5","subtype":"command","commandType":"auto","position":7.0,"command":"top_terms = sqlContext.sql(\"SELECT term, score, tf, link FROM scores WHERE link = 'http://2015.berlinbuzzwords.de/session/machine-learning-startup-big-data-company' ORDER BY score DESC\")\ndisplay(top_terms)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.465216192904E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"8507be40-ecfb-41df-8f91-02b8a6d8a0ce"},{"version":"CommandV1","origId":183210672370557,"guid":"f5e91772-eb0e-413e-989c-23558c9d1550","subtype":"command","commandType":"auto","position":10.0,"command":"def concat(a, b):\n  return '%s %s' % (str(a), str(b))\nsessions_per_year = sqlContext.createDataFrame(sessions.select(\"year\", \"body\").rdd.combineByKey(str, concat, concat).collect(), ['year', 'body'])\nsessions_per_year.registerTempTable(\"sessions_per_year\")\ndisplay(sessions_per_year)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.465216193484E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"a4982b38-ede5-4ecd-9434-fa8688efec74"},{"version":"CommandV1","origId":3160017144901321,"guid":"be270755-0063-43f9-8b06-9523e4cefa45","subtype":"command","commandType":"auto","position":11.0,"command":"tfidf_per_year = run_tf_idf_spark_mllib(sessions_per_year)\n#display(tfidf_per_year.select(\"features\"))\nscores_per_year = sqlContext.createDataFrame(sc.parallelize(idf_scores_for_terms(tfidf_per_year, \"year\")), [\"year\", \"term\", \"score\", \"tf\"])\nscores_per_year.registerTempTable(\"scores_per_year\")","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.465216194121E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"08556fb0-3584-476c-bc59-991ecc2d240e"},{"version":"CommandV1","origId":3160017144901322,"guid":"9abc3d40-a30e-4c3c-b476-0bf6a69750b0","subtype":"command","commandType":"auto","position":12.0,"command":"top_terms_per_year = sqlContext.sql(\"\"\"\nSELECT year, term, score, rank FROM (\n  SELECT year, term, score, dense_rank() OVER (PARTITION BY year ORDER BY score DESC) as rank\n  FROM scores_per_year\n  WHERE score <> 0\n) tmp\nWHERE\n  rank <= 10\nORDER BY year, rank ASC\n\"\"\")\ndisplay(top_terms_per_year)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.465216194745E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"29fda9ae-63dc-427f-aa06-1b70c11cd09e"},{"version":"CommandV1","origId":2219829048372533,"guid":"caa53fed-7ffa-4b0e-b35f-fca1debdf7b1","subtype":"command","commandType":"auto","position":14.0,"command":"# Prove that hashing functions are different in mllib and ml\nmllibHashingTf = MllibHashingTF(numFeatures=numFeatures)\n\ndef indexOf(term):\n    \"\"\" Returns the index of the input term. \"\"\"\n    return hash(term) % numFeatures\n\nwords = first[0].words\nfeatures = first[0].rawFeatures\nfor index, term in enumerate(words):\n    term_index = indexOf(term)\n    print '%s %s %d %f %s' % (index, term, term_index, features[term_index], term_index in features.indices)\n\nprint words\nprint features","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.465216195144E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"Hashing functions are different in mllib and ml","showCommandTitle":true,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"d19ee774-53fd-4caf-b9a0-2b853b8122b3"},{"version":"CommandV1","origId":545167560021769,"guid":"2767fa9d-eb25-4a86-9741-af78f4feba07","subtype":"command","commandType":"auto","position":15.0,"command":"def timeline(terms):\n    return sqlContext.sql(\"\"\"\nSELECT year, term, tf FROM scores_per_year\nWHERE term IN ('%s')\nORDER BY year, tf ASC\n\"\"\" % (\"', '\".join(terms))) ","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.465216195566E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"lineChart","width":"660","height":"auto","xColumns":["year"],"yColumns":["tf"],"pivotColumns":["term"],"pivotAggregation":"sum","customPlotOptions":{"barChart":[{"key":"grouped","value":true},{"key":"stacked","value":false},{"key":"100_stacked","value":false}],"lineChart":[]},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"d0d5677f-cac7-4c0e-b3d1-b577659ec142"},{"version":"CommandV1","origId":2405992306356972,"guid":"0916d40d-b6e4-45c5-8da6-e1711e56c38f","subtype":"command","commandType":"auto","position":15.125,"command":"def timelineRelative(terms):\n    return sqlContext.sql(\"\"\"\nSELECT s.year, term, tf, total, tf / total as relative_tf FROM scores_per_year s LEFT JOIN (SELECT year, sum(tf) as total FROM scores_per_year GROUP BY year) t ON (s.year = t.year)\nWHERE term IN ('%s')\nORDER BY year, tf ASC\n\"\"\" % (\"', '\".join(terms))) ","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.465216361025E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"ead33137-25e3-4ad9-8993-ac15cab96c04"},{"version":"CommandV1","origId":2405992306356974,"guid":"d952a93c-0440-4d64-907f-dc0dfaabeae3","subtype":"command","commandType":"auto","position":15.1875,"command":"display(timelineRelative([\n  'lucene',\n  'solr',\n  'elasticsearch',\n]))   ","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.465216361985E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"lineChart","width":"660","height":"auto","xColumns":["year"],"yColumns":["relative_tf"],"pivotColumns":["term"],"pivotAggregation":"sum","customPlotOptions":{"barChart":[{"key":"grouped","value":true},{"key":"stacked","value":false},{"key":"100_stacked","value":false}],"lineChart":[]},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"dc1ae9fc-5f51-4dc2-8c13-26f1f07b104d"},{"version":"CommandV1","origId":3074177156933419,"guid":"2e42945d-016c-47ba-b8b2-071646b74b86","subtype":"command","commandType":"auto","position":15.25,"command":"display(timeline([\n  'lucene',\n  'solr',\n  'elasticsearch',\n]))   ","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.46521638527E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"lineChart","width":"660","height":"auto","xColumns":["year"],"yColumns":["tf"],"pivotColumns":["term"],"pivotAggregation":"sum","customPlotOptions":{"lineChart":[]},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"6aa91b53-e793-4ab2-ad0f-12b2623c506a"},{"version":"CommandV1","origId":3074177156933415,"guid":"6c248869-33d4-47df-9280-7080f4be2071","subtype":"command","commandType":"auto","position":15.25390625,"command":"display(timeline([\n  'storm',\n  'flink',\n  'spark',\n]))","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.465216505168E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"lineChart","width":"660","height":"auto","xColumns":["year"],"yColumns":["tf"],"pivotColumns":["term"],"pivotAggregation":"sum","customPlotOptions":{"lineChart":[]},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"5ef2e566-797f-4949-907c-37bda2c6d9c7"},{"version":"CommandV1","origId":3074177156933425,"guid":"93bb0d98-7c2a-4f50-89ad-cbf957c9c06f","subtype":"command","commandType":"auto","position":15.40625,"command":"display(timeline([\n  'mapreduce',\n  'hdf',\n  'yarn',\n  'nosql',\n  'sql',\n]))   ","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.465216434095E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"lineChart","width":"660","height":"auto","xColumns":["year"],"yColumns":["tf"],"pivotColumns":["term"],"pivotAggregation":"sum","customPlotOptions":{"lineChart":[]},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"123dd4c2-08fb-40bd-aadb-22a085f8f926"},{"version":"CommandV1","origId":3074177156933421,"guid":"d4a688ff-3705-4d44-a9f4-b26619bf570e","subtype":"command","commandType":"auto","position":15.4375,"command":"display(timeline([\n  'nosql',\n  'sql',\n  'graph',\n]))   ","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.465204169367E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"lineChart","width":"660","height":"auto","xColumns":["year"],"yColumns":["tf"],"pivotColumns":["term"],"pivotAggregation":"sum","customPlotOptions":{"barChart":[{"key":"grouped","value":true},{"key":"stacked","value":false},{"key":"100_stacked","value":false}],"lineChart":[]},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"007ec5d9-957f-4d05-9260-73603dfa7b57"},{"version":"CommandV1","origId":3074177156933414,"guid":"3980a2c2-4a47-4451-a010-6807ea07769c","subtype":"command","commandType":"auto","position":16.0,"command":"display(timeline([\n  'cassandra',\n  'hbase',\n  'redi',\n  'riak',\n  'couchdb',\n  'mongodb',\n]))","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.465204170206E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"lineChart","width":"660","height":"auto","xColumns":["year"],"yColumns":["tf"],"pivotColumns":["term"],"pivotAggregation":"sum","customPlotOptions":{"barChart":[{"key":"grouped","value":true},{"key":"stacked","value":false},{"key":"100_stacked","value":false}],"lineChart":[]},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"40ed323c-41b6-469c-9e7f-eb2181e80ff8"},{"version":"CommandV1","origId":3074177156933416,"guid":"dc0ca86d-290c-4898-8140-68001338324d","subtype":"command","commandType":"auto","position":17.0,"command":"display(timeline([\n  'streaming',\n  'realtime',\n  'batch',\n]))","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.465204170852E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"lineChart","width":"660","height":"auto","xColumns":["year"],"yColumns":["tf"],"pivotColumns":["term"],"pivotAggregation":"sum","customPlotOptions":{"lineChart":[]},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"52ca935a-6595-4a8f-a7f0-a3af14fd270b"},{"version":"CommandV1","origId":3074177156933422,"guid":"233de7c8-bfa5-45b9-8eda-57456485f5a8","subtype":"command","commandType":"auto","position":17.5,"command":"display(timeline([\n  'hive',\n  'pig',\n  'impala',\n  'presto',\n  'sparksql',\n  'drill',\n]))","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.465204171303E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"lineChart","width":"660","height":"auto","xColumns":["year"],"yColumns":["tf"],"pivotColumns":["term"],"pivotAggregation":"sum","customPlotOptions":{"lineChart":[]},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"0b763c78-535c-4176-8641-106e25d75bed"},{"version":"CommandV1","origId":4498040078984375,"guid":"ba1cd456-1d18-4162-96c9-bcbd84a7a646","subtype":"command","commandType":"auto","position":17.75,"command":"display(timeline([\n  'crunch',\n  'eventsourcing',\n]))","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.465204289387E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"lineChart","width":"660","height":"auto","xColumns":["year"],"yColumns":["tf"],"pivotColumns":["term"],"pivotAggregation":"sum","customPlotOptions":{"lineChart":[]},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"789db532-3bd2-4ea7-84d2-f4fc7feec3a1"},{"version":"CommandV1","origId":3074177156933417,"guid":"3590e3da-4cf1-4b3a-8455-c2b797c09681","subtype":"command","commandType":"auto","position":18.0,"command":"old = ['hadoop', 'mapreduce', 'hdf']\nnew = ['spark', 'flink', 'storm']\n\ndisplay(sqlContext.sql(\"\"\"\nSELECT year, CASE WHEN term in ('%s') THEN 'hadoop+mapreduce+hdfs' ELSE 'spark+flink+storm' END AS technology, tf FROM scores_per_year\nWHERE term IN ('%s')\nORDER BY year, tf ASC\n\"\"\" % (\"', '\".join(old), \"', '\".join(old + new))))","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.465204334323E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"lineChart","width":"660","height":"auto","xColumns":["year"],"yColumns":["tf"],"pivotColumns":["technology"],"pivotAggregation":"sum","customPlotOptions":{"barChart":[{"key":"grouped","value":true},{"key":"stacked","value":false},{"key":"100_stacked","value":false}],"lineChart":[]},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"a9fc108e-42b0-4970-9696-33e21b0d7854"},{"version":"CommandV1","origId":3074177156933418,"guid":"649d80d7-111d-49a9-8c0d-098448beaf1d","subtype":"command","commandType":"auto","position":19.0,"command":"display(sqlContext.sql(\"\"\"\nSELECT year, sum(tf) FROM scores_per_year\nGROUP BY year\nORDER BY year ASC\n\"\"\"))","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.465204336973E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"lineChart","width":"660","height":"auto","xColumns":["year"],"yColumns":["_c1"],"pivotColumns":[],"pivotAggregation":"sum","customPlotOptions":{"lineChart":[]},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"bc53f2c6-d5a5-48bc-be2b-a330617d9500"},{"version":"CommandV1","origId":3074177156933423,"guid":"cbcaa9e6-dbd1-4f3b-9c2d-f0e6b1739c2f","subtype":"command","commandType":"auto","position":20.0,"command":"display(sqlContext.sql(\"\"\"\nSELECT term, tf FROM scores_per_year\nWHERE year = 2016\nORDER BY tf DESC LIMIT 20\n\"\"\"))","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.464725981942E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"8d8f8587-f621-4176-9ce8-faf4ad9c309a"},{"version":"CommandV1","origId":3074177156933426,"guid":"34cbfdb3-414e-4d66-9498-1b2fb23e506a","subtype":"command","commandType":"auto","position":21.0,"command":"","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"d651ef4e-b1b6-43cd-a89a-a9154945bccb"},{"version":"CommandV1","origId":2469000391151279,"guid":"2b972fb8-dec4-4a46-bc9f-47324eee8a97","subtype":"command","commandType":"auto","position":21.1875,"command":"dbutils.fs.cp('/databricks-datasets/cs100/lab3/data-001/stopwords.txt', '/mnt/bbuzz2016/stopwords.txt')","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":1.465236204816E12,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"nuid":"21a7beb2-b3e5-444c-bab0-e542f234cfc6"}],"dashboards":[],"guid":"0fdbaeae-e576-4778-a9b0-6cda7f54e059","globalVars":{},"iPythonMetadata":null,"inputWidgets":{}};</script>
<script
 src="https://databricks-prod-cloudfront.cloud.databricks.com/static/201606061046110700-7b6903d79ff87bc92783c273ec9805efdd9a8110/js/notebook-main.js"
 onerror="window.mainJsLoadError = true;"></script>
</head>
<body>
  <script>
if (window.mainJsLoadError) {
  var u = 'https://databricks-prod-cloudfront.cloud.databricks.com/static/201606061046110700-7b6903d79ff87bc92783c273ec9805efdd9a8110/js/notebook-main.js';
  var b = document.getElementsByTagName('body')[0];
  var c = document.createElement('div');
  c.innerHTML = ('<h1>Network Error</h1>' +
    '<p><b>Please check your network connection and try again.</b></p>' +
    '<p>Could not load a required resource: ' + u + '</p>');
  c.style.margin = '30px';
  c.style.padding = '20px 50px';
  c.style.backgroundColor = '#f5f5f5';
  c.style.borderRadius = '5px';
  b.appendChild(c);
}
</script>
</body>
</html>
